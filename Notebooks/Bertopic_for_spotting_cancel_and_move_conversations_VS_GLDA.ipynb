{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4d33856-45fb-4880-8561-40046e39aa15",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Background Knowledge:   \n",
    "## The main goal is to     \n",
    "## 1. Spot customers with conversations related to 'cancel' or 'move', \n",
    "## 2. Spot any other possible topics which co-occur with 'cancel' or 'move' to help understand the reason for deactivations   \n",
    "     \n",
    "## This is a semi-supervised task, the label is the manual category_id tagging from call agents, and each conversations would have unequal quantity of ids.    \n",
    "## If a conversation contains 'cancel' related ids then it is assgined with label 'cancel', same thing applys to 'move'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7b55cef-355c-4968-8cb0-d435d9df9c9c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## The reason for doing topic modeling instead of classification is    \n",
    "### 1. The agent's prior assumption can not be fully trusted    \n",
    "### 2. We do not have accurate ids mapping for other topics like 'promotion inquiry' or 'billing inquiry'   \n",
    "### 3. The total unique number of ids is increasing and some old ids are aborted, which makes the long term dependency for category_id as label unreliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21397cb8-39dc-4678-84b3-42f45e2b2db1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data preparation fucntion blocks\n",
    "## (preprocessing of both customer and agent raw conversations using sparknlp):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84ea2ee3-7b1d-471f-857f-9e31f5745d54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertopic in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (0.14.1)\r\nRequirement already satisfied: sentence-transformers>=0.4.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from bertopic) (2.2.2)\r\nRequirement already satisfied: numpy>=1.20.0 in /databricks/python3/lib/python3.9/site-packages (from bertopic) (1.21.5)\r\nRequirement already satisfied: hdbscan>=0.8.29 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from bertopic) (0.8.29)\r\nRequirement already satisfied: scikit-learn>=0.22.2.post1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from bertopic) (1.1.0)\r\nRequirement already satisfied: pandas>=1.1.5 in /databricks/python3/lib/python3.9/site-packages (from bertopic) (1.4.2)\r\nRequirement already satisfied: plotly>=4.7.0 in /databricks/python3/lib/python3.9/site-packages (from bertopic) (5.6.0)\r\nRequirement already satisfied: umap-learn>=0.5.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from bertopic) (0.5.3)\r\nRequirement already satisfied: tqdm>=4.41.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from bertopic) (4.65.0)\r\nRequirement already satisfied: cython>=0.27 in /databricks/python3/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (0.29.28)\r\nRequirement already satisfied: joblib>=1.0 in /databricks/python3/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (1.1.1)\r\nRequirement already satisfied: scipy>=1.0 in /databricks/python3/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (1.7.3)\r\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\r\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2021.3)\r\nRequirement already satisfied: six in /databricks/python3/lib/python3.9/site-packages (from plotly>=4.7.0->bertopic) (1.16.0)\r\nRequirement already satisfied: tenacity>=6.2.0 in /databricks/python3/lib/python3.9/site-packages (from plotly>=4.7.0->bertopic) (8.0.1)\r\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (2.2.0)\r\nRequirement already satisfied: torchvision in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.15.1)\r\nRequirement already satisfied: torch>=1.6.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (2.0.0)\r\nRequirement already satisfied: nltk in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (3.8.1)\r\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.22.0)\r\nRequirement already satisfied: sentencepiece in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.97)\r\nRequirement already satisfied: huggingface-hub>=0.4.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.13.2)\r\nRequirement already satisfied: pyyaml>=5.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (5.4.1)\r\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /databricks/python3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.1.1)\r\nRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.9.0)\r\nRequirement already satisfied: packaging>=20.9 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (21.3)\r\nRequirement already satisfied: requests in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.28.2)\r\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.4)\r\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (11.7.99)\r\nRequirement already satisfied: jinja2 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\r\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (10.2.10.91)\r\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (11.7.99)\r\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (11.7.101)\r\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (11.7.4.91)\r\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (11.10.3.66)\r\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (11.4.0.1)\r\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.14.3)\r\nRequirement already satisfied: triton==2.0.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.0.0)\r\nRequirement already satisfied: sympy in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.11.1)\r\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (11.7.91)\r\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (10.9.0.58)\r\nRequirement already satisfied: networkx in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.0)\r\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (8.5.0.96)\r\nRequirement already satisfied: wheel in /databricks/python3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (0.37.0)\r\nRequirement already satisfied: setuptools in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (67.6.0)\r\nRequirement already satisfied: lit in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (15.0.7)\r\nRequirement already satisfied: cmake in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.26.0)\r\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.10.31)\r\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.12.1)\r\nRequirement already satisfied: pynndescent>=0.5 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.8)\r\nRequirement already satisfied: numba>=0.49 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.56.4)\r\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.39.1)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.0.1)\r\nRequirement already satisfied: click in /databricks/python3/lib/python3.9/site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.4)\r\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.4)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.9)\r\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2021.10.8)\r\nRequirement already satisfied: mpmath>=0.19 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\r\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.9/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.0.1)\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-69db614e-3176-43fa-892c-a98fb223ca0a/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e99dac0-3b4d-42d1-8cbb-364dda0af220",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Verint:\n",
    "    \"\"\"\n",
    "        This class wraps data operations for verint\n",
    "    \"\"\"\n",
    "\n",
    "    ### Table names & queries on Databricks ###\n",
    "    verint_table = \"VERINT.CBU_ROG_CONVERSATION_SUMFCT\"\n",
    "    booked_table = \"VERINT.SESSIONS_BOOKED\"\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_data_filter(min_date = None, max_date = None, categories = [], instances = [], spark_s = None):\n",
    "        \"\"\"\n",
    "        Loading cbu_rog_conversation_sumfct data to spark dataframes\n",
    "        :param condition: Optional condition to be passed to verint_query e.g. \"where []\"\n",
    "        :return cbu_rog_conversation_sumfct dataframes respectively\n",
    "        \"\"\"\n",
    "        #91 add distinct for sid_key\n",
    "        if instances != [] and categories != []:\n",
    "            print('Categories and instances provided')\n",
    "            #Category id can be used to filter our churned customers\n",
    "            verint_query = \"SELECT * FROM ( \\\n",
    "                (SELECT distinct speech_id FROM \\\n",
    "                (SELECT distinct sid_key FROM VERINT.SESSIONS_CATEGORIES WHERE category_id in ('{0}') AND instance_id in ('{1}')) as category \\\n",
    "                INNER JOIN \\\n",
    "                (SELECT CONCAT(unit_num, '0', channel_num) as speech_id, sid_key FROM {1}) as booked \\\n",
    "                ON booked.sid_key = category.sid_key) as merged \\\n",
    "                INNER JOIN \\\n",
    "                (SELECT distinct SPEECH_ID_VERINT,TEXT_AGENT_FULL, TEXT_CUSTOMER_FULL, TEXT_OVERLAP, TEXT_ALL, CUSTOMER_ID, CTN, \\\n",
    "                AGENT_EMP_ID,CONNECTION_ID,RECEIVING_SKILL,LANGUAGE_INDICATOR, CONVERSATION_DATE, YEAR(conversation_date) as Year, \\\n",
    "                MONTH(conversation_date) as Month FROM {3} WHERE conversation_date >= '{4}') \\\n",
    "                as sumfct ON sumfct.speech_id_verint = merged.speech_id) as final\"\\\n",
    "                .format((\"','\".join(categories)),(\"','\".join(instances)),Verint.booked_table,Verint.verint_table, min_date)\n",
    "        #91 add distinct for sid_key\n",
    "        elif instances == [] and categories != []:\n",
    "            print('Categories provided')\n",
    "            verint_query = \"SELECT * FROM ( \\\n",
    "                (SELECT distinct speech_id FROM \\\n",
    "                (SELECT distinct sid_key FROM VERINT.SESSIONS_CATEGORIES WHERE category_id in ('{0}')) as category \\\n",
    "                INNER JOIN \\\n",
    "                (SELECT CONCAT(unit_num, '0', channel_num) as speech_id, sid_key FROM {1}) as booked \\\n",
    "                ON booked.sid_key = category.sid_key) as merged \\\n",
    "                INNER JOIN \\\n",
    "                (SELECT distinct SPEECH_ID_VERINT,TEXT_AGENT_FULL, TEXT_CUSTOMER_FULL, TEXT_OVERLAP, TEXT_ALL, CUSTOMER_ID, CTN, \\\n",
    "                AGENT_EMP_ID,CONNECTION_ID,RECEIVING_SKILL,LANGUAGE_INDICATOR, CONVERSATION_DATE,  YEAR(conversation_date) as Year, \\\n",
    "                MONTH(conversation_date) as Month FROM {2} WHERE conversation_date >= '{3}') \\\n",
    "                as sumfct ON sumfct.speech_id_verint = merged.speech_id) as final\" \\\n",
    "                .format((\"','\".join(categories)),Verint.booked_table,Verint.verint_table, min_date)\n",
    "        #91 add distinct for sid_key\n",
    "        elif instances != [] and categories == []:\n",
    "            print('Instances provided')\n",
    "            verint_query = \"SELECT * FROM ( \\\n",
    "                (SELECT distinct speech_id FROM \\\n",
    "                (SELECT distinct sid_key FROM VERINT.SESSIONS_CATEGORIES WHERE instance_id in ('{0}')) as category \\\n",
    "                INNER JOIN \\\n",
    "                (SELECT CONCAT(unit_num, '0', channel_num) as speech_id, sid_key FROM {1}) as booked \\\n",
    "                ON booked.sid_key = category.sid_key) as merged \\\n",
    "                INNER JOIN \\\n",
    "                (SELECT distinct SPEECH_ID_VERINT,TEXT_AGENT_FULL, TEXT_CUSTOMER_FULL, TEXT_OVERLAP, TEXT_ALL, CUSTOMER_ID, CTN, \\\n",
    "                AGENT_EMP_ID,CONNECTION_ID,RECEIVING_SKILL,LANGUAGE_INDICATOR, CONVERSATION_DATE,  YEAR(conversation_date) as Year, \\\n",
    "                MONTH(conversation_date) as Month FROM {2} WHERE conversation_date >= '{3}') \\\n",
    "                as sumfct ON sumfct.speech_id_verint = merged.speech_id\"\\\n",
    "                .format((\"','\".join(instances)),Verint.booked_table,Verint.verint_table, min_date)\n",
    "       \n",
    "        else:\n",
    "            print('Only date provided')\n",
    "            verint_query = \"SELECT * FROM (SELECT distinct SPEECH_ID_VERINT,TEXT_AGENT_FULL, TEXT_CUSTOMER_FULL, TEXT_OVERLAP, \\\n",
    "                TEXT_ALL, CUSTOMER_ID, CTN, AGENT_EMP_ID, CONNECTION_ID, RECEIVING_SKILL, \\\n",
    "                LANGUAGE_INDICATOR, CONVERSATION_DATE, YEAR(conversation_date) as Year, MONTH(conversation_date) as Month \\\n",
    "                FROM {1} WHERE conversation_date >= '{2}') as final\" \\\n",
    "                .format(Verint.booked_table, Verint.verint_table, min_date)\n",
    "        \n",
    "        \n",
    "        if max_date is not None:\n",
    "            verint_query = \"{0} where {1}\".format(verint_query, \"conversation_date < '{}'\".format(max_date))\n",
    "            \n",
    "        \n",
    "        return spark_s.sql(verint_query) \n",
    "    @staticmethod\n",
    "    def load_data_filter_not(min_date = None, max_date = None, categories = [], instances = [], spark_s = None):\n",
    "        \"\"\"\n",
    "        Loading cbu_rog_conversation_sumfct data to spark dataframes\n",
    "        :param condition: Optional condition to be passed to verint_query e.g. \"where []\"\n",
    "        :return cbu_rog_conversation_sumfct dataframes respectively\n",
    "        \"\"\"\n",
    "        #91 add distinct for sid_key\n",
    "        if instances != [] and categories != []:\n",
    "            print('Categories and instances provided')\n",
    "            #Category id can be used to filter our churned customers\n",
    "            verint_query = \"SELECT * FROM ( \\\n",
    "                (SELECT distinct speech_id FROM \\\n",
    "                (SELECT distinct sid_key FROM VERINT.SESSIONS_CATEGORIES WHERE category_id not in ('{0}') AND instance_id not in ('{1}')) as category \\\n",
    "                INNER JOIN \\\n",
    "                (SELECT CONCAT(unit_num, '0', channel_num) as speech_id, sid_key FROM {1}) as booked \\\n",
    "                ON booked.sid_key = category.sid_key) as merged \\\n",
    "                INNER JOIN \\\n",
    "                (SELECT distinct SPEECH_ID_VERINT,TEXT_AGENT_FULL, TEXT_CUSTOMER_FULL, TEXT_OVERLAP, TEXT_ALL, CUSTOMER_ID, CTN, \\\n",
    "                AGENT_EMP_ID,CONNECTION_ID,RECEIVING_SKILL,LANGUAGE_INDICATOR, CONVERSATION_DATE, YEAR(conversation_date) as Year, \\\n",
    "                MONTH(conversation_date) as Month FROM {3} WHERE conversation_date >= '{4}') \\\n",
    "                as sumfct ON sumfct.speech_id_verint = merged.speech_id) as final\"\\\n",
    "                .format((\"','\".join(categories)),(\"','\".join(instances)),Verint.booked_table,Verint.verint_table, min_date)\n",
    "        #91 add distinct for sid_key\n",
    "        elif instances == [] and categories != []:\n",
    "            print('Categories provided')\n",
    "            verint_query = \"SELECT * FROM ( \\\n",
    "                (SELECT distinct speech_id FROM \\\n",
    "                (SELECT distinct sid_key FROM VERINT.SESSIONS_CATEGORIES WHERE category_id not in ('{0}')) as category \\\n",
    "                INNER JOIN \\\n",
    "                (SELECT CONCAT(unit_num, '0', channel_num) as speech_id, sid_key FROM {1}) as booked \\\n",
    "                ON booked.sid_key = category.sid_key) as merged \\\n",
    "                INNER JOIN \\\n",
    "                (SELECT distinct SPEECH_ID_VERINT,TEXT_AGENT_FULL, TEXT_CUSTOMER_FULL, TEXT_OVERLAP, TEXT_ALL, CUSTOMER_ID, CTN, \\\n",
    "                AGENT_EMP_ID,CONNECTION_ID,RECEIVING_SKILL,LANGUAGE_INDICATOR, CONVERSATION_DATE,  YEAR(conversation_date) as Year, \\\n",
    "                MONTH(conversation_date) as Month FROM {2} WHERE conversation_date >= '{3}') \\\n",
    "                as sumfct ON sumfct.speech_id_verint = merged.speech_id) as final\" \\\n",
    "                .format((\"','\".join(categories)),Verint.booked_table,Verint.verint_table, min_date)\n",
    "        #91 add distinct for sid_key\n",
    "        elif instances != [] and categories == []:\n",
    "            print('Instances provided')\n",
    "            verint_query = \"SELECT * FROM ( \\\n",
    "                (SELECT distinct speech_id FROM \\\n",
    "                (SELECT distinct sid_key FROM VERINT.SESSIONS_CATEGORIES WHERE instance_id not in ('{0}')) as category \\\n",
    "                INNER JOIN \\\n",
    "                (SELECT CONCAT(unit_num, '0', channel_num) as speech_id, sid_key FROM {1}) as booked \\\n",
    "                ON booked.sid_key = category.sid_key) as merged \\\n",
    "                INNER JOIN \\\n",
    "                (SELECT distinct SPEECH_ID_VERINT,TEXT_AGENT_FULL, TEXT_CUSTOMER_FULL, TEXT_OVERLAP, TEXT_ALL, CUSTOMER_ID, CTN, \\\n",
    "                AGENT_EMP_ID,CONNECTION_ID,RECEIVING_SKILL,LANGUAGE_INDICATOR, CONVERSATION_DATE,  YEAR(conversation_date) as Year, \\\n",
    "                MONTH(conversation_date) as Month FROM {2} WHERE conversation_date >= '{3}') \\\n",
    "                as sumfct ON sumfct.speech_id_verint = merged.speech_id\"\\\n",
    "                .format((\"','\".join(instances)),Verint.booked_table,Verint.verint_table, min_date)\n",
    "       \n",
    "        else:\n",
    "            print('Only date provided')\n",
    "            verint_query = \"SELECT * FROM (SELECT distinct SPEECH_ID_VERINT,TEXT_AGENT_FULL, TEXT_CUSTOMER_FULL, TEXT_OVERLAP, \\\n",
    "                TEXT_ALL, CUSTOMER_ID, CTN, AGENT_EMP_ID, CONNECTION_ID, RECEIVING_SKILL, \\\n",
    "                LANGUAGE_INDICATOR, CONVERSATION_DATE, YEAR(conversation_date) as Year, MONTH(conversation_date) as Month \\\n",
    "                FROM {1} WHERE conversation_date >= '{2}') as final\" \\\n",
    "                .format(Verint.booked_table, Verint.verint_table, min_date)\n",
    "        \n",
    "        if max_date is not None:\n",
    "            verint_query = \"{0} where {1}\".format(verint_query, \"conversation_date < '{}'\".format(max_date))\n",
    "            \n",
    "        return spark_s.sql(verint_query) \n",
    "\n",
    "class Household:\n",
    "    \"\"\"\n",
    "        This class wraps data operations for household\n",
    "    \"\"\"\n",
    "\n",
    "    ### Table names & queries on Databricks ###\n",
    "    # household_table = \"APP_IBRO.IBRO_HOUSEHOLD_ACTIVITY\"\n",
    "    household_table= \"ml_etl_output_data.IBRO_HOUSEHOLD_ACTIVITY_CHURN_SCHEDULED\"\n",
    "    # nonchurn_table = \"DEFAULT.IBRO_HOUSEHOLD_ACTIVITY_NONCHURN_SCHEDULED\"\n",
    "    # change the nonchurn table for new cluster\n",
    "    nonchurn_table = \"ml_etl_output_data.IBRO_HOUSEHOLD_ACTIVITY_NONCHURN_SCHEDULED\"\n",
    "    all_household= \"ml_etl_output_data.IBRO_HOUSEHOLD_ACTIVITY_SCHEDULED\"\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data(spark_s = None, churn = None):\n",
    "        \"\"\"\n",
    "        Loading ibro_household_activity data to spark dataframes\n",
    "        :param condition: Optional condition to be passed to household_query e.g. \"where []\"\n",
    "        :return ibro_household_activity dataframes respectively\n",
    "        \"\"\"\n",
    "\n",
    "        # those columns can be used to filter our churned customers\n",
    "        # find out CAN, treated as account_number\n",
    "        # ARPA_OUT = -1 means deac, ARPA_OUT = 1 means winback\n",
    "        if churn is None:\n",
    "            household_query = \"select * from {0}\".format(Household.all_household)\n",
    "            \n",
    "        elif churn == True:\n",
    "            household_query = \"select * from {0}\".format(Household.household_table)\n",
    "\n",
    "        elif churn == False:\n",
    "            household_query = \"select * from {0}\".format(Household.nonchurn_table)\n",
    "\n",
    "        return spark_s.sql(household_query) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "628b8414-dae3-49fa-80d6-e70b93c48c0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ORD_NUM = [\n",
    "'first',\n",
    "'second',\n",
    "'third',\n",
    "'fourth',\n",
    "'fifth',\n",
    "'sixth',\n",
    "'seventh',\n",
    "'eighth',\n",
    "'ninth',\n",
    "'tenth',\n",
    "'eleventh',\n",
    "'twelfth',\n",
    "'thirteenth',\n",
    "'fourteenth',\n",
    "'fifteenth',\n",
    "'sixteenth',\n",
    "'seventeenth',\n",
    "'eighteenth',\n",
    "'nineteenth',\n",
    "'twentieth',\n",
    "'thirtieth',\n",
    "'twenty first',\n",
    "'twenty second',\n",
    "'twenty third',\n",
    "'twenty fourth',\n",
    "'twenty fifth',\n",
    "'twenty sixth',\n",
    "'twenty seventh',\n",
    "'twenty eighth',\n",
    "'twenty ninth',\n",
    "'thirty first']\n",
    "\n",
    "NUMBERS = [\n",
    "'zero',\n",
    "'one',\n",
    "'two',\n",
    "'three',\n",
    "'four',\n",
    "'five',\n",
    "'six',\n",
    "'seven',\n",
    "'eight',\n",
    "'nine',\n",
    "'ten',\n",
    "'eleven',\n",
    "'twelve',\n",
    "'thirteen',\n",
    "'fourteen',\n",
    "'fifteen',\n",
    "'sixteen',\n",
    "'seventeen',\n",
    "'eighteen',\n",
    "'nineteen',\n",
    "'twenty',\n",
    "'thirty',\n",
    "'forty',\n",
    "'fifty',\n",
    "'sixty',\n",
    "'seventy',\n",
    "'eighty',\n",
    "'ninety',\n",
    "'hundred',\n",
    "'thousand']\n",
    "\n",
    "MONTH = [\n",
    "'january',\n",
    "'jan',\n",
    "'february',\n",
    "'feb',\n",
    "'march',\n",
    "'mar',\n",
    "'april',\n",
    "'apr',\n",
    "'may',\n",
    "'june',\n",
    "'jun',\n",
    "'july',\n",
    "'jul',\n",
    "'august',\n",
    "'aug',\n",
    "'september',\n",
    "'sep',\n",
    "'october',\n",
    "'oct',\n",
    "'november',\n",
    "'nov',\n",
    "'december',\n",
    "'dec']\n",
    "\n",
    "DAYS = [\n",
    "'monday',\n",
    "'mon',\n",
    "'tuesday',\n",
    "'tue',\n",
    "'wednesday',\n",
    "'wed',\n",
    "'thursday',\n",
    "'thu',\n",
    "'friday',\n",
    "'fri',\n",
    "'saturday',\n",
    "'sat',\n",
    "'sunday',\n",
    "'sun']\n",
    "\n",
    "\n",
    "BOLDCHAT_STOPWORDS = ['week', 'thank', 'thanks', 'ask', 'ago', 'im', 'sure', 'sound', 'mean', 'lot',\n",
    "                      'look', 'ok', 'okay', 'thats', 'yes', 'want', 'couple', 'correct', 'use', 'nice',\n",
    "                      'good', 'day', 'let', 'great', 'fine', 'hi', 'hope', 'already', 'also', 'able',\n",
    "                      'could', 'else', 'etc', 'guy', 'hello', 'hey', 'however', 'lol', 'maybe',\n",
    "                      'might', 'morning', 'nope', 'oh', 'perfect', 'please', 'right', 'since', 'someone',\n",
    "                      'sorry', 'still', 'though', 'thx', 'well', 'today', 'wonder', 'would', 'yeah',\n",
    "                      'yet', 'even', 'believe', 'think', 'wish', 'mind', 'plz', 'glad', 'say',\n",
    "                      'possible', 'sept', 'be', 'i', 'the', 'a', 'will', 'mo', 'instead', 'pls', 'go',\n",
    "                      'of', 'the', 'that', 'to', 'do', 'for', 'if', 'need', 'tomorrow', 'simply',\n",
    "                     'in', 'but', 'or', 'and', 'about', 'just', 'have', 'an', 'on', 'know', 'not',\n",
    "                     'yesterday', 'today', 'try', 'google', 'research', 'appreciate', 'help', 'like',\n",
    "                     'oct', 'aug', 'jun', 'july', 'nov', 'dec', 'stay', 'safe', 'tell', 'bye',\n",
    "                     'speak', 'chat']\n",
    "BOLDCHAT_FINAL_STOPWORDS=['still', 'for', 'sound', 'appreciate', 'could', 'please', 'about', 'july', 'want', \n",
    "'since', 'yesterday', 'though', 'hey', 'aug', 'hi', 'yeah', 'a', 'right', 'wish', 'great', 'nov', \n",
    "'simply', 'perfect', 'even', 'lot', 'might', 'morning', 'today', 'be', 'help', 'mo', 'someone', 'fine',\n",
    " 'that', 'to', 'not', 'believe', 'ok', 'else', 'glad', 'hello', 'nope', 'sorry', 'google', 'thats', \n",
    " 'plz', 'guy', 'hope', 'possible', 'well', 'jun', 'yes', 'wonder', 'mind', 'research', 'lol', 'sept',\n",
    "  'couple', 'already', 'pls', 'i', 'thx', 'but', 'the', 'try', 'im', 'instead', 'just', 'have', 'and',\n",
    " 'or', 'thanks', 'week', 'let', 'like', 'also', 'in', 'if', 'think', 'oct', 'thank', 'need', 'will',\n",
    " 'correct', 'maybe', 'however', 'of', 'oh', 'nice', 'okay', 'dec', 'do', 'on', 'an', 'ask', 'look',\n",
    " 'would', 'bye', 'good', 'ago', 'tomorrow', 'day', 'mean', 'etc', 'sure', 'yet']\n",
    "\n",
    "ALL_BOLDCHAT_STOPWORDS = set(ORD_NUM + NUMBERS + MONTH + DAYS + BOLDCHAT_FINAL_STOPWORDS)\n",
    "\n",
    "\n",
    "FINAL_INTERNAL_STOPWORDS_ALIGN = ['actually', 'better', 'was', 'how', 'for', 'could', 'please', 'then',\n",
    "  'whereupon', 'so', 'consider', 'as', 'any', 'used', 'brief', 'why', 'several', 'hi', 'six', 'by', \n",
    "  'hence', 'yourself', 'k', 'looking', 'right', 'saying', 'fifth', 'wish', 'did', \"there's\", 'whose',\n",
    "  'uses', 'inward', 'appear', 'doing', 'n’t', 'doesnt', 'her', 'yourselves', 'nothing', 'not', 'believe',\n",
    "  '‘ve', 'thereby', 'got', 'took', \"c's\", 'forty', 'each', \"we've\", 'whether', 'gets', 'obviously',\n",
    "  'serious', 'inner', 'perhaps', 'me', 'necessary', 'gotten', 'nevertheless', 'furthermore', 'looks',\n",
    "  'somebody', 'rather', 'elsewhere', 'former', 'seemed', 'away', 'up', 'than', 'except', 'via', 'can',\n",
    "  'everything', \"you've\", 'already', 'along', 'currently', 'while', 'selves', 'anyone', 'our', \n",
    "  'thus', 'Shes', 'must', 'either', 'c', \"c'mon\", 'try', 'wants', 'welcome', '’ve', 'between', \n",
    "  'ever', 'z', 'does', 'whereafter', 'twelve', 'apart', 'ca', 'gone', 'awfully', 'came', 'let', \n",
    "  'like', 'in', 'u', 'getting', 'again', 'taken', 'itself', 'themselves', 'thank', 'need', 'until',\n",
    "  'whence', 'she', 'no', 'us', \"they'll\", 'normally', 'amongst', 'greetings', 'nearly', 'despite',\n",
    "  'hither', \"i'll\", 'consequently', 'were', 'whole', 'couldnt', 'knows', 'nine', 'everywhere', \n",
    "  'under', 'mainly', 'thanx', 'an', 'corresponding', 'therein', 'would', 'containing', 'causes', \n",
    "  'beyond', 'near', 'become', \"you're\", 'etc', 'liked', \"doesn't\", 'seriously', 'sure', 's', \n",
    "  'asking', 'uucp', 'sixty', 'gives', 'merely', 'myself', 'they', 'about', \"hasn't\", 'ie', 'st', \n",
    "  'indicates', 'far', \"i'd\", 'since', 'put', 'amount', 'whatever', 'whereby', 'though', 'lately',\n",
    "  'nd', 'thru', \"isn't\", \"that's\", 'a', \"haven't\", \"hadn't\", \"'ll\", 'never', 'cant', 'saw', 'viz',\n",
    "  'theres', 'their', 'unlikely', 'even', 'ours', 'twenty', \"can't\", 'am', 'mo', 'jus', 'someone',\n",
    "  'that', \"'s\", 'last', 'to', 'd', \"he's\", \"couldn't\", 'becoming', 'placed', 'upon', 'one', \n",
    "  'this', 'meanwhile', 'more', 'else', 'usually', 'definitely', 'hello', \"who's\", 'himself', \n",
    "  'moreover', 'bottom', 'tends', 'possible', 'well', 'regardless', \"shouldn't\", 'became',\n",
    "  'reasonably', 'same', 'b', 'everybody', 'gonna', 'j', 'alone', 'self', '‘d', 'theyd', \n",
    "  'these', \"wasn't\", 'before', 'needs', 'goes', 'with', 'but', 'because', 'went', 'following',\n",
    "  'hers', 'really', 'thereupon', 'thorough', 'third', 'always', 'described', \"we'll\", 'some',\n",
    "  \"'ve\", 'associated', 'ivent', 'thanks', \"i've\", 'seen', 'think', 'hereby', 'his', \"what's\",\n",
    "  'above', 'going', 'part', 'twice', 'wont', 'th', 'few', 'hows', 'formerly', \"'d\", 'insofar',\n",
    "  'sensible', 'happens', 'maybe', 'however', '’d', 'seeming', 'having', 'co', 'somewhere', \n",
    "  'him', 'neither', 'okay', 'do', 'whereas', 'according', 'particularly', 'ask', 'howbeit',\n",
    "  'o', 'besides', 'wherein', \"they've\", 'contains', 'next', 'throughout', 'against', 'edu',\n",
    "  'et', 'is', 'unless', 'yet', 'therefore', 'many', 'eight', 'still', 'name', 'certainly', \n",
    "  'nobody', 'mine', 'top', 'sup', 'somehow', 'you', 'anybody', 'eg', 'overall', 'been', 'fifty', \n",
    "  'sometimes', 'where', 'hereafter', 'three', 'g', 'quite', 'towards', 'made', 'may', 'gotta', 'side',\n",
    "  'thereafter', 'beside', 'noone', 'none', 'be', 'anywhere', 'further', 'help', '‘ll', 'accordingly',\n",
    "  'specifying', 'toward', 'due', \"you'll\", 'hopefully', 'my', 'what', 'p', 'youre', 'pl', 'beforehand',\n",
    "  'there', 'secondly', 'shes', \"we're\", 'thence', 'ignored', 'forth', 'indicated', 'together', 'four',\n",
    "  'hardly', 'useful', 'kept', 'sub', 'yes', 'among', 'at', 'q', \"n't\", 'ex', 'such', 'considering', \n",
    "  't', 'using', 'something', 'ourselves', 'r', 'keep', \"wouldn't\", 'y', 'another', 'clearly', 'onto', \n",
    "  'im', 'given', 'latterly', '‘s', 'dont', 'especially', 'seeing', 'appropriate', 'later', 'had', 'or', \n",
    "  'only', 'provides', 'ididnt', 'hundred', 'whenever', 'anyways', 'also', 'itd', 'see', '‘re', 'havent', \n",
    "  'best', 'whither', \"aren't\", 'less', 'allows', 'lest', 'much', 'others', 'n', 'should', 'immediate', \n",
    "  'although', 'around', 'sometime', 'example', 'seem', 'entirely', \"they're\", 'que', 'Im', 'arent', \n",
    "  'of', 'l', 'oh', 'down', 'five', 'them', 'allow', 'on', \"you'd\", 'followed', '‘m', 'yours', 'regard', \n",
    "  'somewhat', 'tried', 'very', 'thoroughly', 'various', 'empty', 'shall', \"weren't\", 'e', \"it'll\", \n",
    "  'through', 'wherever', 'most', 'cannot', \"it's\", 'here', 'thatll', 'namely', \"don't\", 'mostly', \n",
    "  'during', 'per', 'v', 'whoever', 'out', 'we', \"let's\", 'course', 'qv', 'alls', 'appreciate', '’re', \n",
    "  'want', 'both', 're', 'ten', 'h', 'm', 'anyhow', 'after', 'back', 'trying', 'wasnt', 'everyone', \n",
    "  'done', 'often', 'regards', 'concerning', 'w', 'presumably', 'oops', 'hasnt', \"they'd\", \"ain't\", \n",
    "  'latter', 'might', 'seems', 'now', 'take', 'unto', 'says', 'certain', 'fifteen', \"won't\", 'every', \n",
    "  'own', '’m', 'truly', 'becomes', 'sent', 'likely', 'all', 'ok', 'make', 'sorry', 'which', 'full', \n",
    "  'indeed', 'thats', 'nor', 'give', 'other', 'almost', 'unfortunately', 'hereupon', 'who', 'wonder', \n",
    "  'nowhere', \"here's\", \"i'm\", 'willing', 'youll', '’s', \"'re\", 'rd', 'com', 'changes', 'said', 'too', \n",
    "  'exactly', 'tries', 'x', \"didn't\", 'ive', 'he', 'i', 'vs', \"it'd\", 'particular', 'its', 'inasmuch', \n",
    "  'those', 'probably', 'the', 'contain', 'it', 'first', 'herein', 'hes', '’ll', 'instead', 'ones', \n",
    "  'indicate', 'just', 'specify', 'over', \"a's\", 'have', 'and', \"we'd\", \"'m\", 'specified', 'when', \n",
    "  'relatively', 'eleven', 'below', 'if', 'f', 'theirs', 'behind', 'whom', 'didnt', 'are', 'will', \n",
    "  \"where's\", 'from', 'into', 'enough', 'least', 'your', 'anyway', 'n‘t', 'un', \"t's\", 'cause', \n",
    "  'herself', 'keeps', 'ought', 'has', 'within', 'comes', 'once', 'novel', 'front', 'anything', 'known', \n",
    "  'afterwards', 'aside', 'look', 'being', 'off', 'across', 'mean', 'respectively', 'value', 'two', \n",
    "  'otherwise', 'Dont', 'isnt', 'regarding', 'without', 'follows', 'ltd', 'pci','#pci#','#PCI#']\n",
    "\n",
    "FRENCH_STOPWORDS = [\"a\",\"abord\",\"absolument\",\"afin\",\"ah\",\"ai\",\"aie\",\"aient\",\"aies\",\"ailleurs\",\"ainsi\",\"ait\",\"allaient\",\n",
    "                    \"allo\",\"allons\",\"allô\",\"alors\",\"anterieur\",\"anterieure\",\"anterieures\",\"apres\",\"après\",\"as\",\"assez\",\n",
    "                    \"attendu\",\"au\",\"aucun\",\"aucune\",\"aucuns\",\"aujourd\",\"aujourd'hui\",\"aupres\",\"auquel\",\"aura\",\"aurai\",\n",
    "                    \"auraient\",\"aurais\",\"aurait\",\"auras\",\"aurez\",\"auriez\",\"aurions\",\"aurons\",\"auront\",\"aussi\",\"autant\",\n",
    "                    \"autre\",\"autrefois\",\"autrement\",\"autres\",\"autrui\",\"aux\",\"auxquelles\",\"auxquels\",\"avaient\",\"avais\",\n",
    "                    \"avait\",\"avant\",\"avec\",\"avez\",\"aviez\",\"avions\",\"avoir\",\"avons\",\"ayant\",\"ayez\",\"ayons\",\"b\",\"bah\",\n",
    "                    \"bas\",\"basee\",\"bat\",\"beau\",\"beaucoup\",\"bien\",\"bigre\",\"bon\",\"boum\",\"bravo\",\"brrr\",\"c\",\"car\",\"ce\",\n",
    "                    \"ceci\",\"cela\",\"celle\",\"celle-ci\",\"celle-là\",\"celles\",\"celles-ci\",\"celles-là\",\"celui\",\"celui-ci\",\n",
    "                    \"celui-là\",\"celà\",\"cent\",\"cependant\",\"certain\",\"certaine\",\"certaines\",\"certains\",\"certes\",\"ces\",\"cet\",\n",
    "                    \"cette\",\"ceux\",\"ceux-ci\",\"ceux-là\",\"chacun\",\"chacune\",\"chaque\",\"cher\",\"chers\",\"chez\",\"chiche\",\"chut\",\"chère\",\n",
    "                    \"chères\",\"ci\",\"cinq\",\"cinquantaine\",\"cinquante\",\"cinquantième\",\"cinquième\",\"clac\",\"clic\",\"combien\",\n",
    "                    \"comme\",\"comment\",\"comparable\",\"comparables\",\"compris\",\"concernant\",\"contre\",\"couic\",\"crac\",\"d\",\"da\",\n",
    "                    \"dans\",\"de\",\"debout\",\"dedans\",\"dehors\",\"deja\",\"delà\",\"depuis\",\"dernier\",\"derniere\",\"derriere\",\"derrière\",\n",
    "                    \"des\",\"desormais\",\"desquelles\",\"desquels\",\"dessous\",\"dessus\",\"deux\",\"deuxième\",\"deuxièmement\",\"devant\",\n",
    "                    \"devers\",\"devra\",\"devrait\",\"different\",\"differentes\",\"differents\",\"différent\",\"différente\",\"différentes\",\n",
    "                    \"différents\",\"dire\",\"directe\",\"directement\",\"dit\",\"dite\",\"dits\",\"divers\",\"diverse\",\"diverses\",\"dix\",\"dix-huit\",\n",
    "                    \"dix-neuf\",\"dix-sept\",\"dixième\",\"doit\",\"doivent\",\"donc\",\"dont\",\"dos\",\"douze\",\"douzième\",\"dring\",\"droite\",\n",
    "                    \"du\",\"duquel\",\"durant\",\"dès\",\"début\",\"désormais\",\"e\",\"effet\",\"egale\",\"egalement\",\"egales\",\"eh\",\"elle\",\n",
    "                    \"elle-même\",\"elles\",\"elles-mêmes\",\"en\",\"encore\",\"enfin\",\"entre\",\"envers\",\"environ\",\"es\",\"essai\",\"est\",\n",
    "                    \"et\",\"etant\",\"etc\",\"etre\",\"eu\",\"eue\",\"eues\",\"euh\",\"eurent\",\"eus\",\"eusse\",\"eussent\",\"eusses\",\"eussiez\",\n",
    "                    \"eussions\",\"eut\",\"eux\",\"eux-mêmes\",\"exactement\",\"excepté\",\"extenso\",\"exterieur\",\"eûmes\",\"eût\",\"eûtes\",\"f\",\n",
    "                    \"fais\",\"faisaient\",\"faisant\",\"fait\",\"faites\",\"façon\",\"feront\",\"fi\",\"flac\",\"floc\",\"fois\",\"font\",\"force\",\n",
    "                    \"furent\",\"fus\",\"fusse\",\"fussent\",\"fusses\",\"fussiez\",\"fussions\",\"fut\",\"fûmes\",\"fût\",\"fûtes\",\"g\",\"gens\",\"h\",\n",
    "                    \"ha\",\"haut\",\"hein\",\"hem\",\"hep\",\"hi\",\"ho\",\"holà\",\"hop\",\"hormis\",\"hors\",\"hou\",\"houp\",\"hue\",\"hui\",\"huit\",\n",
    "                    \"huitième\",\"hum\",\"hurrah\",\"hé\",\"hélas\",\"i\",\"ici\",\"il\",\"ils\",\"importe\",\"j\",\"je\",\"jusqu\",\"jusque\",\"juste\",\n",
    "                    \"k\",\"l\",\"la\",\"laisser\",\"laquelle\",\"las\",\"le\",\"lequel\",\"les\",\"lesquelles\",\"lesquels\",\"leur\",\"leurs\",\"longtemps\",\n",
    "                    \"lors\",\"lorsque\",\"lui\",\"lui-meme\",\"lui-même\",\"là\",\"lès\",\"m\",\"ma\",\"maint\",\"maintenant\",\"mais\",\"malgre\",\n",
    "                    \"malgré\",\"maximale\",\"me\",\"meme\",\"memes\",\"merci\",\"mes\",\"mien\",\"mienne\",\"miennes\",\"miens\",\"mille\",\"mince\",\n",
    "                    \"mine\",\"minimale\",\"moi\",\"moi-meme\",\"moi-même\",\"moindres\",\"moins\",\"mon\",\"mot\",\"moyennant\",\"multiple\",\n",
    "                    \"multiples\",\"même\",\"mêmes\",\"n\",\"na\",\"naturel\",\"naturelle\",\"naturelles\",\"ne\",\"neanmoins\",\"necessaire\",\n",
    "                    \"necessairement\",\"neuf\",\"neuvième\",\"ni\",\"nombreuses\",\"nombreux\",\"nommés\",\"non\",\"nos\",\"notamment\",\"notre\",\n",
    "                    \"nous\",\"nous-mêmes\",\"nouveau\",\"nouveaux\",\"nul\",\"néanmoins\",\"nôtre\",\"nôtres\",\"o\",\"oh\",\"ohé\",\"ollé\",\"olé\",\n",
    "                    \"on\",\"ont\",\"onze\",\"onzième\",\"ore\",\"ou\",\"ouf\",\"ouias\",\"oust\",\"ouste\",\"outre\",\"ouvert\",\"ouverte\",\"ouverts\",\n",
    "                    \"o|\",\"où\",\"p\",\"paf\",\"pan\",\"par\",\"parce\",\"parfois\",\"parle\",\"parlent\",\"parler\",\"parmi\",\"parole\",\"parseme\",\n",
    "                    \"partant\",\"particulier\",\"particulière\",\"particulièrement\",\"pas\",\"passé\",\"pendant\",\"pense\",\"permet\",\"personne\",\n",
    "                    \"personnes\",\"peu\",\"peut\",\"peuvent\",\"peux\",\"pff\",\"pfft\",\"pfut\",\"pif\",\"pire\",\"pièce\",\"plein\",\"plouf\",\n",
    "                    \"plupart\",\"plus\",\"plusieurs\",\"plutôt\",\"possessif\",\"possessifs\",\"possible\",\"possibles\",\"pouah\",\"pour\",\n",
    "                    \"pourquoi\",\"pourrais\",\"pourrait\",\"pouvait\",\"prealable\",\"precisement\",\"premier\",\"première\",\"premièrement\",\n",
    "                    \"pres\",\"probable\",\"probante\",\"procedant\",\"proche\",\"près\",\"psitt\",\"pu\",\"puis\",\"puisque\",\"pur\",\"pure\",\"q\",\n",
    "                    \"qu\",\"quand\",\"quant\",\"quant-à-soi\",\"quanta\",\"quarante\",\"quatorze\",\"quatre\",\"quatre-vingt\",\"quatrième\",\n",
    "                    \"quatrièmement\",\"que\",\"quel\",\"quelconque\",\"quelle\",\"quelles\",\"quelqu'un\",\"quelque\",\"quelques\",\"quels\",\n",
    "                    \"qui\",\"quiconque\",\"quinze\",\"quoi\",\"quoique\",\"r\",\"rare\",\"rarement\",\"rares\",\"relative\",\"relativement\",\n",
    "                    \"remarquable\",\"rend\",\"rendre\",\"restant\",\"reste\",\"restent\",\"restrictif\",\"retour\",\"revoici\",\"revoilà\",\n",
    "                    \"rien\",\"s\",\"sa\",\"sacrebleu\",\"sait\",\"sans\",\"sapristi\",\"sauf\",\"se\",\"sein\",\"seize\",\"selon\",\"semblable\",\n",
    "                    \"semblaient\",\"semble\",\"semblent\",\"sent\",\"sept\",\"septième\",\"sera\",\"serai\",\"seraient\",\"serais\",\"serait\",\n",
    "                    \"seras\",\"serez\",\"seriez\",\"serions\",\"serons\",\"seront\",\"ses\",\"seul\",\"seule\",\"seulement\",\"si\",\"sien\",\"sienne\",\n",
    "                    \"siennes\",\"siens\",\"sinon\",\"six\",\"sixième\",\"soi\",\"soi-même\",\"soient\",\"sois\",\"soit\",\"soixante\",\"sommes\",\n",
    "                    \"son\",\"sont\",\"sous\",\"souvent\",\"soyez\",\"soyons\",\"specifique\",\"specifiques\",\"speculatif\",\"stop\",\"strictement\",\n",
    "                    \"subtiles\",\"suffisant\",\"suffisante\",\"suffit\",\"suis\",\"suit\",\"suivant\",\"suivante\",\"suivantes\",\"suivants\",\n",
    "                    \"suivre\",\"sujet\",\"superpose\",\"sur\",\"surtout\",\"t\",\"ta\",\"tac\",\"tandis\",\"tant\",\"tardive\",\"te\",\"tel\",\"telle\",\n",
    "                    \"tellement\",\"telles\",\"tels\",\"tenant\",\"tend\",\"tenir\",\"tente\",\"tes\",\"tic\",\"tien\",\"tienne\",\"tiennes\",\"tiens\",\n",
    "                    \"toc\",\"toi\",\"toi-même\",\"ton\",\"touchant\",\"toujours\",\"tous\",\"tout\",\"toute\",\"toutefois\",\"toutes\",\"treize\",\n",
    "                    \"trente\",\"tres\",\"trois\",\"troisième\",\"troisièmement\",\"trop\",\"très\",\"tsoin\",\"tsouin\",\"tu\",\"té\",\"u\",\"un\",\"une\",\n",
    "                    \"unes\",\"uniformement\",\"unique\",\"uniques\",\"uns\",\"v\",\"va\",\"vais\",\"valeur\",\"vas\",\"vers\",\"via\",\"vif\",\"vifs\",\n",
    "                    \"vingt\",\"vivat\",\"vive\",\"vives\",\"vlan\",\"voici\",\"voie\",\"voient\",\"voilà\",\"voire\",\"vont\",\"vos\",\"votre\",\"vous\",\n",
    "                    \"vous-mêmes\",\"vu\",\"vé\",\"vôtre\",\"vôtres\",\"w\",\"x\",\"y\",\"z\",\"zut\",\"à\",\"â\",\"ça\",\"ès\",\"étaient\",\"étais\",\"était\",\n",
    "                    \"étant\",\"état\",\"étiez\",\"étions\",\"été\",\"étée\",\"étées\",\"étés\",\"êtes\",\"être\",\"ô\"]\n",
    "\n",
    "ENGLISH_STOPWORDS = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', \n",
    "                     'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', \n",
    "                     'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'few', \n",
    "                     'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \n",
    "                     \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \n",
    "                     \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most',\n",
    "                     \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', \n",
    "                     'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \n",
    "                     \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', \n",
    "                     'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', \n",
    "                     'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \n",
    "                     \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \n",
    "                     \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', \n",
    "                     'yourself', 'yourselves']\n",
    "\n",
    "VERINT_STOPWORDS = ['okay', 'believe', 'june', 'to', 'use', 'happen', 'without', 'dont', 'yet', 'blah',\n",
    "                    'morning', 'thanks', 'little', 'please', 'perfect', 'sorry', 'think', 'ca', 'blah blah',\n",
    "                    'guy', 'else', 'call', 'hey', 'however', 'thats', 'thx', 'say', 'every', 'try', 'blah blah blah',\n",
    "                    'sure', 'come', 'uh', 'well', 'seem', 'yeah', 'know', 'fine', 'might', 'hello', 'password', 'passwords',\n",
    "                    'want', 'tell', 'ok', 'since', 'cant', 'take', 'sir', 'two', 'maybe', 'im', 'great', 'hold',\n",
    "                    'oh', 'one', 'chat', 'already', 'nope', 'thank', 'someone', 'roger', 'today', 'give',\n",
    "                    'good', 'hi', 'bye', 'could', 'also', 'would', 'look', 'find', 'may', 'show', 'alright',\n",
    "                    'wonder', 'still', 'need', 'actually', 'mean', 'ago', 'rogers', 'go', 'yes',\n",
    "                    'right', 'though', 'get', 'wait', 'etc', 'see', 'let', 'even', 'august', 'july', 'thing',\n",
    "                    'lol', 'like', 'um', 'stuff', 'pci', 'com', 'dot', 'yahoo', 'underscore', 'date', 'birth',\n",
    "                   'postal', 'code', 'number', 'email', 'dollar', 'cent', 'buck', 'gmail', 'hotmail',\"leave\", \"message\", \n",
    "                   \"tone\", \"leave\", \"hang\", \"press\", \"pound\", \"option\", \"est\", \"que\",\"pas\",\"vous\",\"euh\",\"oui\",\"pour\",\"moi\",\"parce\",\n",
    "                   \"mais\", \"people\" , \"est\" , \"year\",  \"company\", \"kind\" , \"point\" , \"plus\" , \"card\" , \"way\" , \"person\" , \"non\" , \n",
    "                   \"big\" , \"letter\" , \"pour\" , \"happy\" , \"start\" , \"live\" , \"door\" , \"money\", \"best\" , \"car\" , \"family\" ,\"dollars\" , \n",
    "                   \"school\" , \"son\" , \"building\" , \"absolutely\" ,  \"god\" , \"everybody\",\"husband\", \"wife\", \"mom\", \"dad\", \"black\",\n",
    "                   \"gonna\", \"son\", \"daughter\", \"white\", \"guys\", \"bien\", \"mois\", \"puis\", \"vai\", \"cinq\", \"bye\", \"goodbye\", \"blue\",\n",
    "                   \"color\", \"anymore\", \"worry\", \"somebody\"]\n",
    "\n",
    "VERINT_FINAL_STOPWORDS=['still', 'mom', 'actually', 'pour', 'pas', 'guys', 'little', 'could', 'please', 'july', 'want', 'point',\n",
    " 'blah blah', 'tone', 'since', 'car', 'moi', 'though', 'hey', 'sir', 'hi', 'birth', 'vous', 'letter',\n",
    "  'yeah', 'worry', 'big', 'underscore', 'right', 'great', 'may', 'cant', 'perfect', 'even', 'might',\n",
    "  'today', 'morning', 'door', 'take', 'vai', 'someone', 'fine', 'happy', 'to', 'believe', 'every',\n",
    "  'one', 'school', 'gmail', 'ok', 'wife', 'else', 'hotmail', 'hello', 'nope', 'sorry', 'cent', 'son',\n",
    "  'thats', 'guy', 'give', 'dad', 'well', 'press', 'somebody', 'wonder', 'yes', 'everybody', 'gonna',\n",
    "  'cinq', 'lol', 'com', 'people', 'already', 'dot', 'june', 'stuff', 'person', 'blah', 'black', \n",
    "  'uh', 'thx', 'yahoo', 'pound', 'kind', 'money', 'color', 'try', 'im', 'um', 'puis', 'blah blah blah',\n",
    "  'dollar', 'dont', 'mois', 'est', 'absolutely', 'ca', 'thanks', 'let', 'like', 'also', 'august',\n",
    "  'see', 'happen', 'best', 'passwords', 'dollars', 'think', 'alright', 'buck', 'thank', 'need',\n",
    "  'parce', 'pci', 'seem', 'que', 'thing', 'euh', 'maybe', 'hang', 'however', 'oh', 'daughter',\n",
    "  'mais', 'blue', 'okay', 'husband', 'building', 'look', 'bye', 'would', 'live', 'white', 'good', \n",
    "  'ago', 'goodbye', 'mean', 'god', 'bien', 'etc', 'two', 'sure', 'yet', 'without', 'oui']\n",
    "ALL_VERINT_STOPWORDS = set(ORD_NUM + NUMBERS + MONTH + DAYS + VERINT_FINAL_STOPWORDS + BOLDCHAT_FINAL_STOPWORDS + FRENCH_STOPWORDS + ENGLISH_STOPWORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99aee3bb-ca8b-46a6-b211-72c1763c40c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sparknlp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from datetime import datetime\n",
    "import re\n",
    "import string\n",
    "\n",
    "class VerintETL:\n",
    "    \"\"\"\n",
    "    This class covers the required functionalities to perform\n",
    "    primilinary ETL jobs on cbu_rog_conversation_sumfct\n",
    "    to prepare an integraded dateset for the Normalizer Pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    sumfct_keep_cols = [\n",
    "                        'TEXT_CUSTOMER_FULL',\n",
    "                        'TEXT_AGENT_FULL',\n",
    "                        'TEXT_ALL',\n",
    "                        'RECEIVING_SKILL',\n",
    "                        'CTN',\n",
    "                        'CUSTOMER_ID',\n",
    "                        'SPEECH_ID_VERINT',\n",
    "                        'CONVERSATION_DATE',\n",
    "                        'Year',\n",
    "                        'Month',\n",
    "                        'CONNECTION_ID'\n",
    "                        ]\n",
    "    # interaction_id corrupted\n",
    "    # sumfct_keep_cols suggested ['TEXT_CUSTOMER_FULL','TEXT_AGENT_FULL','TEXT_ALL','CUSTOMER_ID','CTN',\n",
    "    #      'SPEECH_ID_VERINT', 'CONNECTION_ID', 'RECEIVING_SKILL', 'CONVERSATION_DATE','Year','Month']\n",
    "    def __init__(self, verint_sumfct_df):\n",
    "        \"\"\"\n",
    "        :param verint_df: Spark DataFrame containing raw cbu_rog_conversation_sumfct for a given time period\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        verint_sumfct_df = verint_sumfct_df.distinct()\n",
    "        self.verint_sumfct_df = verint_sumfct_df\n",
    "        # self.household_df = household_df\n",
    "\n",
    "        # load data later than set date\n",
    "        # last_load = \"2021-03-10\"\n",
    "        #self.verint_df = self.__last_load_input_data(self.verint_sumfct_df, last_load)\n",
    "        #self.logger.info(\"Number of verint records: {}\".format(self.verint_df.count()))\n",
    "        # filter for only consumer vqs\n",
    "        #self.verint_df = self.__filter_input_data(self.verint_df, self.consumer_vq_df)\n",
    "        #self.logger.info(\"Number of verint records: {}\".format(self.verint_df.count()))\n",
    "\n",
    "        # keep necessary columns only\n",
    "        self.verint_df = self.verint_sumfct_df.select(VerintETL.sumfct_keep_cols)\n",
    "        print(\"count rows: {}\".format(self.verint_df.count()))\n",
    "        self.verint_df = self.verint_df.distinct()\n",
    "        \n",
    "        # self.merge_df = self.__merge_df(self.verint_df, self.household_df)\n",
    "        \n",
    "        # self.merge_df = self.merge_df.distinct()\n",
    "        print(\"distinct count rows: {}\".format(self.verint_df.count()))\n",
    "        print(\"full consumer rows\")\n",
    "        self.logger.info(\"Number of verint records: {}\".format(self.verint_df.count()))\n",
    "        try:\n",
    "            assert (self.verint_df.count() > 0)\n",
    "        except AssertionError:\n",
    "            self.logger.error(\"The joined Verint dataframe is empty.\")\n",
    "\n",
    "    def __last_load_input_data(self, verint_sumfct_df, last_load):\n",
    "        \"\"\"\n",
    "        Filtering data later than set date\n",
    "        :return: DF that loaded later than set date\n",
    "        \"\"\"\n",
    "\n",
    "        sum_date_counts = verint_sumfct_df.groupBy('record_insert_dt').count().sort('record_insert_dt').collect()\n",
    "        sum_date_dict = {}\n",
    "\n",
    "        for row in sum_date_counts:\n",
    "            sum_date_dict[row['record_insert_dt']] = row['count']\n",
    "        verint_sumfct_df = verint_sumfct_df.where(verint_sumfct_df.record_insert_dt > last_load)\n",
    "        return verint_sumfct_df\n",
    "\n",
    "\n",
    "    def __filter_input_data(self, verint_sumfct_df, consumer_vq_df):\n",
    "        \"\"\"\n",
    "        Filtering for only consumer vqs\n",
    "        :return: joined verint sumfct DF\n",
    "        \"\"\"\n",
    "        # join condition\n",
    "        print(\"join\")\n",
    "        join_cond = [consumer_vq_df.VQ == verint_sumfct_df.receiving_skill]\n",
    "        return verint_sumfct_df.join(consumer_vq_df, join_cond, 'inner')\n",
    "    \n",
    "\n",
    "    def __get_batch_start_date_and_end_date(self, verint_df):\n",
    "        print(\"new data rows\")\n",
    "        print(verint_df.count())\n",
    "        if verint_df.count() == 0:\n",
    "            sys.exit('No new data loaded')\n",
    "        load_date_counts = verint_df.groupBy('record_insert_dt').count().sort('record_insert_dt').collect()\n",
    "        load_date_dict = {}\n",
    "        for row in load_date_counts:\n",
    "            load_date_dict[row['record_insert_dt']] = row['count']\n",
    "        new_last_load = sorted(load_date_dict.keys())[-1]\n",
    "        new_first_load = sorted(load_date_dict.keys())[0]\n",
    "        print(f'load date range from {new_first_load} to {new_last_load}')\n",
    "        new_last_load = new_last_load.replace(\"-\", \"\")\n",
    "        new_first_load = new_first_load.replace(\"-\", \"\")\n",
    "        return (new_last_load, new_first_load)\n",
    "\n",
    "    ############################\n",
    "    #### Spark Transformers ####\n",
    "    ############################\n",
    "\n",
    "    def __filter_by_receiving_skill(self, receiving_skill):\n",
    "        \"\"\"\n",
    "            Transformer function for filtering the verint data based on receiving_skill (cabel, wireless, etc.)\n",
    "        \"\"\"\n",
    "        print(\"cable skill\")\n",
    "        def transform(verint_df):\n",
    "            return verint_df.where(\"receiving_skill LIKE '%\\_{}\\_%'\".format(receiving_skill))\n",
    "        return transform\n",
    "\n",
    "\n",
    "    def __wireless_cable_vqs(self, verint_df):\n",
    "        \"\"\"\n",
    "        Get wireless and vqs\n",
    "        :return: filtered verint DF\n",
    "        \"\"\"\n",
    "        print(\"wireless or cable vqs\")\n",
    "        return verint_df.where(\n",
    "            \"receiving_skill LIKE 'ROG\\_EN\\_%' AND (receiving_skill LIKE '%\\_WIR%' OR receiving_skill LIKE '%\\_CBL%')\")\n",
    "\n",
    "    def __wireless_cable(self, cbl, wir):\n",
    "        def cbl_wir(verint_df):\n",
    "            return verint_df.where(\n",
    "                \"receiving_skill LIKE '%\\_{0}%' OR receiving_skill LIKE '%\\_{1}%'\".format(cbl, wir))\n",
    "        return cbl_wir\n",
    "\n",
    "\n",
    "    def __msg_not_empty_spark(self, token_col):\n",
    "        \"Removing all the records with no value for the customer message (empty messages)\" #91\n",
    "        def curry(verint_df):\n",
    "            msg_not_empty_udf = udf(lambda msg: len(msg) > 1, BooleanType())\n",
    "            return verint_df.where(msg_not_empty_udf(verint_df[token_col])).drop(token_col)\n",
    "        return curry\n",
    "      \n",
    "    def __msg_not_empty(self, msg_col):\n",
    "        \"Removing all the records with no value for the customer message (empty messages)\" \n",
    "        def curry(verint_df):\n",
    "            msg_not_empty_udf = udf(lambda msg: len(msg.strip()) > 0 , BooleanType())\n",
    "            return verint_df.where(msg_not_empty_udf(verint_df[msg_col]))\n",
    "        return curry\n",
    "\n",
    "    def __extract_cus_msg_spark(self, verint_df):\n",
    "        verint_df_col=list(verint_df.columns)\n",
    "        if \"CLEAN_TEXT_CUSTOMER\" in verint_df_col:\n",
    "            input_col=\"AGENT\"\n",
    "        else:\n",
    "            input_col=\"CUSTOMER\"\n",
    "        if input_col==\"CUSTOMER\":\n",
    "            first=\"TEXT_CUSTOMER_FULL\"\n",
    "        else:\n",
    "            first=\"TEXT_AGENT_FULL\"\n",
    "        documentAssembler = DocumentAssembler() \\\n",
    "            .setInputCol(first) \\\n",
    "            .setOutputCol(\"document\")\n",
    "\n",
    "        documentNormalizer1 = DocumentNormalizer() \\\n",
    "            .setInputCols(\"document\") \\\n",
    "            .setOutputCol(\"normalizedDocument1\") \\\n",
    "            .setAction(\"clean\") \\\n",
    "            .setPatterns([\"e mail\"]) \\\n",
    "            .setReplacement(\"email\") \\\n",
    "            .setPolicy(\"pretty_all\") \\\n",
    "            .setLowercase(True)\n",
    "        \n",
    "        documentNormalizer2 = DocumentNormalizer() \\\n",
    "            .setInputCols(\"normalizedDocument1\") \\\n",
    "            .setOutputCol(\"normalizedDocument2\") \\\n",
    "            .setAction(\"clean\") \\\n",
    "            .setPatterns([\"caller d\"]) \\\n",
    "            .setReplacement(\"caller id\") \\\n",
    "            .setPolicy(\"pretty_all\") \\\n",
    "            .setLowercase(True)\n",
    "\n",
    "        documentNormalizer3 = DocumentNormalizer() \\\n",
    "            .setInputCols(\"normalizedDocument2\") \\\n",
    "            .setOutputCol(\"normalizedDocument3\") \\\n",
    "            .setAction(\"clean\") \\\n",
    "            .setPatterns([\"datum\"]) \\\n",
    "            .setReplacement(\"data\") \\\n",
    "            .setPolicy(\"pretty_all\") \\\n",
    "            .setLowercase(True)\n",
    "        \n",
    "        documentNormalizer4 = DocumentNormalizer() \\\n",
    "            .setInputCols(\"normalizedDocument3\") \\\n",
    "            .setOutputCol(\"normalizedDocument4\") \\\n",
    "            .setAction(\"clean\") \\\n",
    "            .setPatterns([\"’\"]) \\\n",
    "            .setReplacement(\"'\") \\\n",
    "            .setPolicy(\"pretty_all\")\n",
    "          \n",
    "        tokenizer = Tokenizer() \\\n",
    "            .setInputCols([\"normalizedDocument4\"]) \\\n",
    "            .setOutputCol(\"token\")\n",
    "      \n",
    "        normalizer1 = Normalizer() \\\n",
    "            .setInputCols([\"token\"]) \\\n",
    "            .setOutputCol(\"nonDigitTokens\") \\\n",
    "            .setLowercase(True)\\\n",
    "            .setCleanupPatterns([\"\"\"[0-9]\"\"\"])\n",
    " \n",
    "        lemmatizer = LemmatizerModel.pretrained() \\\n",
    "            .setInputCols([\"nonDigitTokens\"]) \\\n",
    "            .setOutputCol(\"lemma\")\n",
    "  \n",
    "        stopwords_cleaner = StopWordsCleaner() \\\n",
    "            .setInputCols([\"lemma\"]) \\\n",
    "            .setOutputCol(\"cleanTokens1\")\\\n",
    "            .setStopWords(list(ALL_VERINT_STOPWORDS))\n",
    "        #91\n",
    "        stopWords = StopWordsCleaner()\\\n",
    "            .setInputCols([\"cleanTokens1\"])\\\n",
    "            .setOutputCol(\"cleanTokens2\")\\\n",
    "            .setStopWords(FINAL_INTERNAL_STOPWORDS_ALIGN)\n",
    "        \n",
    "        normalizer2 = Normalizer() \\\n",
    "            .setInputCols([\"cleanTokens2\"]) \\\n",
    "            .setOutputCol(\"onlyAlphaTokens_\"+input_col) \\\n",
    "            .setLowercase(True)\\\n",
    "            .setCleanupPatterns([\"\"\"[^A-Za-z]\"\"\"]) #91 only keep alphabet letters, could remove \"+\"       \n",
    "        \n",
    "        #91 outputasarray -> true\n",
    "        finisher = Finisher() \\\n",
    "            .setInputCols([\"onlyAlphaTokens_\"+input_col]) \\\n",
    "            .setOutputCols(\"CLEAN_TEXT_\"+input_col) \\\n",
    "            .setOutputAsArray(False)\\\n",
    "            .setCleanAnnotations(False)\\\n",
    "            .setAnnotationSplitSymbol(\" \")\n",
    "\n",
    "        nlp_pipeline = Pipeline(\n",
    "            stages=\n",
    "            [documentAssembler, documentNormalizer1, documentNormalizer2,documentNormalizer3, documentNormalizer4,  tokenizer, normalizer1, lemmatizer,  stopwords_cleaner, stopWords, normalizer2, finisher]\n",
    "        )\n",
    "        verint_df_col.append(\"CLEAN_TEXT_\"+input_col)\n",
    "        verint_df_col.append(\"onlyAlphaTokens_\"+input_col)\n",
    "        print(verint_df_col)\n",
    "        return nlp_pipeline\\\n",
    "            .fit(verint_df)\\\n",
    "            .transform(verint_df).select(verint_df_col)            \n",
    "\n",
    "    def __drop_for_extracting_cus_msg(self, verint_df):\n",
    "        print(\"drop for extracting customer msg\")\n",
    "        return verint_df.drop('TEXT_AGENT_FULL', 'TEXT_OVERLAP', 'TEXT_UNKNOWN')\n",
    "\n",
    "    def __text_df(self, verint_df):\n",
    "        return verint_df.where(length('CLEAN_TEXT_CUSTOMER') > 0)\n",
    "\n",
    "\n",
    "    def __no_text_df(self, verint_df):\n",
    "        return verint_df.where(length('CLEAN_TEXT_CUSTOMER') == 0)\n",
    "\n",
    "    def __competitor_mention(self, verint_df):\n",
    "        print(\"competitor mention\")\n",
    "        comp_udf = udf(VerintETL.competitor_mention, StringType())\n",
    "        return verint_df.withColumn(\"COMPETITOR_MENTION\", comp_udf(verint_df['CLEAN_TEXT_CUSTOMER']))\n",
    "    \n",
    "    def __product_mention(self, verint_df):\n",
    "        print(\"product mention\")\n",
    "        comp_udf = udf(VerintETL.product_mention, StringType())\n",
    "        return verint_df.withColumn(\"PRODUCT_MENTION\", comp_udf(verint_df['CLEAN_TEXT_CUSTOMER']))\n",
    "\n",
    "    def __rogers_fido_mention(self, verint_df):\n",
    "        print(\"rogers fido mention\")\n",
    "        comp_udf = udf(VerintETL.rogers_fido_mention, StringType())\n",
    "        return verint_df.withColumn(\"ROGERS_FIDO_MENTION\", comp_udf(verint_df['CLEAN_TEXT_CUSTOMER']))\n",
    "\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Cable Service ETL ####\n",
    "    ##########################\n",
    "\n",
    "    def get_verint_df(self):\n",
    "        return self.verint_df\n",
    "    \n",
    "    # def get_household_df(self):\n",
    "    #     return self.household_df\n",
    "\n",
    "    def en_rogers_fido_mention_etl(self, df):\n",
    "        return df \\\n",
    "            .transform(self.__filter_by_receiving_skill('EN')) \\\n",
    "            .transform(self.__rogers_fido_mention)\n",
    "\n",
    "    ##########################\n",
    "    ### Wireless Service ETL ####\n",
    "    ##########################\n",
    "\n",
    "    def en_product_mention_etl(self, df):\n",
    "        return df \\\n",
    "            .transform(self.__filter_by_receiving_skill('EN')) \\\n",
    "            .transform(self.__product_mention) \n",
    "\n",
    "        # removed a line: .transform(self.__wireless_cable('CBL', 'WIR')) \\\n",
    "\n",
    "            \n",
    "    def cbl_ser_etl_spark(self):\n",
    "        return self.verint_df \\\n",
    "            .transform(self.__extract_cus_msg_spark)\\\n",
    "            .transform(self.__msg_not_empty_spark(\"onlyAlphaTokens_CUSTOMER\"))\\\n",
    "            .transform(self.__extract_cus_msg_spark)\\\n",
    "            .transform(self.__msg_not_empty_spark(\"onlyAlphaTokens_AGENT\"))\\\n",
    "            .transform(self.__competitor_mention)\\\n",
    "            .transform(self.__rogers_fido_mention)\n",
    "    ##########################\n",
    "    ### Wireless Service ETL ####\n",
    "    ##########################\n",
    "      \n",
    "    def wir_ser_etl_spark(self):\n",
    "        return self.verint_df \\\n",
    "            .transform(self.__wireless_cable_vqs) \\\n",
    "            .transform(self.__filter_by_receiving_skill('WIR')) \\\n",
    "            .transform(self.__extract_cus_msg_spark)\\\n",
    "            .transform(self.__msg_not_empty_spark(\"onlyAlphaTokens_CUSTOMER\"))\\\n",
    "            .transform(self.__drop_for_extracting_cus_msg)\n",
    "    ###########################\n",
    "    #### helper functions ####\n",
    "    ###########################\n",
    "    def no_text_result(df):\n",
    "        def add_na(ph):\n",
    "            return 'N/A'\n",
    "        add_na_udf = udf(add_na, StringType())\n",
    "        df = df.withColumn('Top_1_topic', lit('Undefined'))\n",
    "        df = df.withColumn('Top_2_topic', lit('Undefined'))\n",
    "        df = df.withColumn('Top_1_prob', lit(1.0))\n",
    "        df = df.withColumn('Top_2_prob', lit(1.0))\n",
    "        df = df.withColumn('Top_1_keyword', add_na_udf(df.Top_1_topic))\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def competitor_mention(msg):\n",
    "        comp_list = ['Bell','Telus','Cogeco','Freedom','Virgin','TekSavvy','Shaw','Public Mobile','Chatr','Koodo','Fonus'] # 'Fido', 'Rogers'\n",
    "        men_list = []\n",
    "        msg_list = msg.split()\n",
    "        for comp in comp_list:\n",
    "            if comp.lower() in msg_list:\n",
    "                men_list.append(comp)\n",
    "        return \" | \".join(men_list)\n",
    "    \n",
    "    @staticmethod\n",
    "    def rogers_fido_mention(msg):\n",
    "        comp_list = ['Rogers','Fido']\n",
    "        men_list = []\n",
    "        msg_list = msg.split()\n",
    "        for comp in comp_list:\n",
    "            if comp.lower() in msg_list:\n",
    "                men_list.append(comp)\n",
    "        return \" | \".join(men_list)\n",
    "    \n",
    "    @staticmethod\n",
    "    def product_mention(msg):\n",
    "        men_list = []\n",
    "        prod_dict = {\"ignite smartstream\": \"Ignite SmartStream\", \"ignite smart stream\": \"Ignite SmartStream\",\n",
    "                     \"smartstream\": \"Ignite SmartStream\", \"smart stream\": \"Ignite SmartStream\",\n",
    "                     \"ignite tv\": \"Ignite TV\", \"tv\": \"Ignite TV\",\n",
    "                     \"ignite internet\": \"Ignite Internet\", \"internet\": \"Ignite Internet\",\n",
    "                     \"ignite bundles\": \"Ignite Bundles\", \"bundles\": \"Ignite Bundles\", \n",
    "                     \"smart home\": \"Smart Home\", \"smarthome\": \"Smart Home\",\n",
    "                     \"wireless home internet\": \"Wireless Home Internet\", \"wireless home\": \"Wireless Home Internet\",\n",
    "                     \"wireless internet\": \"Wireless Home Internet\"\n",
    "                     }\n",
    "        for key, val in prod_dict.items():\n",
    "            if key.lower() in msg:\n",
    "                if val.lower() not in men_list:\n",
    "                    men_list.append(val)\n",
    "        return \" | \".join(men_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87067ec7-3296-4a5d-8844-ea403cef1dd1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Generate testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1779593-e102-4ec1-9017-0bf954dd7d8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import *\n",
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)\n",
    "\n",
    "from sparknlp.base import *\n",
    "from pyspark.ml import Pipeline\n",
    "data = spark.createDataFrame([[\"Spark NLP is an open-source text processing library.\"]]).toDF(\"text\")\n",
    "documentAssembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "result = documentAssembler.transform(data)\n",
    "print(result)\n",
    "\n",
    "logger = logging.getLogger(\"Churn_ETL_test\")\n",
    "\n",
    "\n",
    "####Additional testing\n",
    "###we have to process the data for 2 days ago. yesterday's data is not available\n",
    "# today = datetime.today() - timedelta(hours=5)\n",
    "#today = datetime.today()\n",
    "today = datetime.strptime(\"2023-03-08\", '%Y-%m-%d')\n",
    "min_date = (today - timedelta(days=91)).strftime('%Y-%m-%d')\n",
    "max_date = (today - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "# min_date = (today - timedelta(days=5)).strftime('%Y-%m-%d') \n",
    "# max_date = (today - timedelta(days=4)).strftime('%Y-%m-%d')\n",
    "\n",
    "# min_date <= conversation_date < max_date\n",
    "\n",
    "# \" ***** min_date should be read from a parameter storage on Azure, assigning manually for now **** \"\n",
    "\n",
    "# min_date = '2022-09-10'\n",
    "# max_date = '2022-09-11'\n",
    "print(min_date)\n",
    "print(max_date)\n",
    "\n",
    "###################################\n",
    "## Creating a VerintETL Object ##\n",
    "## to perform ETL jobs on the    ##\n",
    "## input data.                   ##\n",
    "###################################\n",
    "\n",
    "\n",
    "spark_session = spark\n",
    "#verint= Verint.load_data(min_date = min_date, max_date = max_date, spark_s = spark_session) \n",
    "# # 1. load cumfct table\n",
    "\n",
    "#verint= Verint.load_data(min_date = min_date, max_date = max_date, categories = ('101000264', '101001648', '109000006', '109000011'), spark_s = spark_session) \n",
    "#verint= Verint.load_data_filter(min_date = min_date, max_date = max_date, categories = ['101000264', '101001648', '109000006', '109000011'], spark_s = spark_session) \n",
    "verint1= Verint.load_data_filter(min_date = min_date, max_date = max_date, spark_s = spark_session)\n",
    "print(verint1.count())\n",
    "\n",
    "#moves\n",
    "# verint2 = Verint.load_data_filter(min_date='2022-03-01', max_date='2022-07-01', categories = ['109000011'],spark_s = spark_session)\n",
    "# verint2= verint2.drop(verint2.speech_id)\n",
    "# print(verint2.count())\n",
    "\n",
    "# verint=verint1.union(verint2).drop_duplicates()\n",
    "verint = verint1\n",
    "print(\"=======================verint columns===============================\")\n",
    "print(verint.columns)\n",
    "\n",
    "# 2. merge before etl transformation\n",
    "#make sure non-churn customers does not appear in churn customers\n",
    "household_df_nonchurn = Household.load_data(spark_s = spark_session, churn = False)\n",
    "print(\"=======================household columns===============================\")\n",
    "print(household_df_nonchurn.columns)\n",
    "household_df_churn = Household.load_data(spark_s = spark_session, churn = True)\n",
    "print(\"=======================household columns===============================\")\n",
    "print(household_df_churn.columns)\n",
    "household_df_churn=household_df_churn.select(\"HASH_LKP_ACCOUNT\").distinct()\n",
    "#retain only left dataset for non-matched records during join\n",
    "household_df=household_df_nonchurn.join(household_df_churn, household_df_nonchurn.HASH_LKP_ACCOUNT ==  household_df_churn.HASH_LKP_ACCOUNT,\"leftanti\")\n",
    "\n",
    "ibro_verint_df = verint.join(household_df, verint.CUSTOMER_ID == household_df.HASH_LKP_ACCOUNT, 'inner')\\\n",
    "    .drop(household_df.CUSTOMER_ID)\\\n",
    "    .drop(household_df.CUSTOMER_COMPANY)\\\n",
    "    .drop(household_df.CUSTOMER_ACCOUNT)\\\n",
    "    .drop(household_df.REPORT_DATE)\n",
    "## moving .drop(verint.account_number) because no such column\n",
    "\n",
    "print(\"=======================merged ibro and verint===============================\")\n",
    "print(ibro_verint_df.columns)\n",
    "print(\"ibro_verint count rows: {}\".format(ibro_verint_df.count()))\n",
    "\n",
    "# verint_etl = VerintETL(verint)\n",
    "\n",
    "verint_etl = VerintETL(ibro_verint_df) \n",
    "verint_df = verint_etl.cbl_ser_etl_spark() # preprocess\n",
    "final_df = verint_etl.en_product_mention_etl(verint_df) # 3. merge as transformation\n",
    "\n",
    "print(\"======================preprocess===============================\")\n",
    "print(final_df.count())\n",
    "temp_path=\"dbfs:/mnt/ml-model-output-scores-data/mlmodel_output/digital/CD4MT/Verint/GLDA_Topic_Modelling_Output/Connected_Home/cancel_and_move_bertopic\"\n",
    "final_df.write.mode(\"overwrite\").option(\"header\", True).parquet(temp_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5795379-59bb-413b-9c57-6356b8b0090a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp_path=\"dbfs:/mnt/ml-model-output-scores-data/mlmodel_output/digital/CD4MT/Verint/GLDA_Topic_Modelling_Output/Connected_Home/cancel_and_move_bertopic\"\n",
    "final_df=spark.read.parquet(temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7355e18e-ceb3-45ee-a5a6-039c3747a875",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Join with inference results by Guided-LDA model for side-to-side model comparsion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "458c80ca-7b21-4ee7-af2f-007f6478cce8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396353\n"
     ]
    }
   ],
   "source": [
    "cm_glda=spark.sql(\"\"\"select \n",
    "SPEECH_ID_VERINT,\n",
    "top_topic,\n",
    "2nd_topic,\n",
    "3rd_topic,\n",
    "4th_topic,\n",
    "5th_topic,\n",
    "lda_inference_result,\n",
    "cancel,\n",
    "move,\n",
    "cancel_mention,\n",
    "move_mention from default.glda_model_df_final_one_month\"\"\")\n",
    "print(cm_glda.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08cf9ecf-77e0-4ce1-875e-8557d1838877",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361714\n"
     ]
    }
   ],
   "source": [
    "comparsion_df=final_df.join(cm_glda,\"SPEECH_ID_VERINT\",how=\"inner\")\n",
    "print(comparsion_df.count())\n",
    "#comparsion_df_pd=comparsion_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8863061-9cf3-4a7b-afd1-72822d880c70",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Generate training data for bert-topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "915d3c75-e246-455f-9f50-cbe3d4674365",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories provided\nCategories provided\nCategories provided\n=======================household columns===============================\n['ACCOUNT_NUMBER', 'REPORT_DATE', 'ARPA_OUT', 'CUSTOMER_ID', 'CUSTOMER_COMPANY', 'CUSTOMER_ACCOUNT', 'ENTERPRISE_ID', 'MULTI_BRAND', 'VOL_INVOL_IND', 'PLATFORM', 'ACTIVITY_GRADE_CODE', 'HASH_LKP_ACCOUNT', 'HASH_LKP_ECID']\n=======================merged ibro and verint===============================\n['speech_id', 'SPEECH_ID_VERINT', 'TEXT_AGENT_FULL', 'TEXT_CUSTOMER_FULL', 'TEXT_OVERLAP', 'TEXT_ALL', 'CUSTOMER_ID', 'CTN', 'AGENT_EMP_ID', 'CONNECTION_ID', 'RECEIVING_SKILL', 'LANGUAGE_INDICATOR', 'CONVERSATION_DATE', 'Year', 'Month', 'ACCOUNT_NUMBER', 'ARPA_OUT', 'ENTERPRISE_ID', 'MULTI_BRAND', 'VOL_INVOL_IND', 'PLATFORM', 'ACTIVITY_GRADE_CODE', 'HASH_LKP_ACCOUNT', 'HASH_LKP_ECID']\nibro_verint count rows: 144832\ncount rows: 141605\ndistinct count rows: 140992\nfull consumer rows\nlemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[ / ]\r[OK!]\n['TEXT_CUSTOMER_FULL', 'TEXT_AGENT_FULL', 'TEXT_ALL', 'RECEIVING_SKILL', 'CTN', 'CUSTOMER_ID', 'SPEECH_ID_VERINT', 'CONVERSATION_DATE', 'Year', 'Month', 'CONNECTION_ID', 'CLEAN_TEXT_CUSTOMER', 'onlyAlphaTokens_CUSTOMER']\nlemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[OK!]\n['TEXT_CUSTOMER_FULL', 'TEXT_AGENT_FULL', 'TEXT_ALL', 'RECEIVING_SKILL', 'CTN', 'CUSTOMER_ID', 'SPEECH_ID_VERINT', 'CONVERSATION_DATE', 'Year', 'Month', 'CONNECTION_ID', 'CLEAN_TEXT_CUSTOMER', 'CLEAN_TEXT_AGENT', 'onlyAlphaTokens_AGENT']\ncompetitor mention\nrogers fido mention\ncable skill\nproduct mention\n"
     ]
    }
   ],
   "source": [
    "min_date = '2022-02-22'\n",
    "max_date = '2022-06-25'\n",
    "\n",
    "###################################\n",
    "## Creating a VerintETL Object ##\n",
    "## to perform ETL jobs on the    ##\n",
    "## input data.                   ##\n",
    "###################################\n",
    "spark_session = spark\n",
    "#verint= Verint.load_data(min_date = min_date, max_date = max_date, spark_s = spark_session) \n",
    "# # 1. load cumfct table\n",
    "\n",
    "#verint= Verint.load_data(min_date = min_date, max_date = max_date, categories = ('101000264', '101001648', '109000006', '109000011'), spark_s = spark_session) \n",
    "#verint= Verint.load_data_filter(min_date = min_date, max_date = max_date, spark_s = spark_session) \n",
    "#cancel only\n",
    "verint1= Verint.load_data_filter(min_date = min_date, max_date = max_date, categories = ['101000264', '101001648', '109000006'], spark_s = spark_session)\n",
    "\n",
    "#move only\n",
    "verint3=Verint.load_data_filter(min_date = min_date, max_date = max_date, categories = ['109000011'], spark_s = spark_session)\n",
    "\n",
    "#micellous merge, for shorter time sake, change min date to 4-19, as long as we get miscellous it is fine\n",
    "verint2 = Verint.load_data_filter_not(min_date = '2022-04-19', max_date = max_date, categories = ['101000264', '101001648', '109000006', '109000011'], spark_s = spark_session)\n",
    "\n",
    "# 2. merge before etl transformation\n",
    "household_df = Household.load_data(spark_s = spark_session, churn = False)\n",
    "print(\"=======================household columns===============================\")\n",
    "print(household_df.columns)\n",
    "\n",
    "ibro_verint_df1 = verint1.join(household_df, verint1.CUSTOMER_ID == household_df.HASH_LKP_ACCOUNT, 'inner')\\\n",
    "    .drop(household_df.CUSTOMER_ID)\\\n",
    "    .drop(household_df.CUSTOMER_COMPANY)\\\n",
    "    .drop(household_df.CUSTOMER_ACCOUNT)\\\n",
    "    .drop(household_df.REPORT_DATE).limit(30000)\n",
    "ibro_verint_df2 = verint2.join(household_df, verint2.CUSTOMER_ID == household_df.HASH_LKP_ACCOUNT, 'inner')\\\n",
    "    .drop(household_df.CUSTOMER_ID)\\\n",
    "    .drop(household_df.CUSTOMER_COMPANY)\\\n",
    "    .drop(household_df.CUSTOMER_ACCOUNT)\\\n",
    "    .drop(household_df.REPORT_DATE).limit(90000)\n",
    "ibro_verint_df3 = verint3.join(household_df, verint3.CUSTOMER_ID == household_df.HASH_LKP_ACCOUNT, 'inner')\\\n",
    "    .drop(household_df.CUSTOMER_ID)\\\n",
    "    .drop(household_df.CUSTOMER_COMPANY)\\\n",
    "    .drop(household_df.CUSTOMER_ACCOUNT)\\\n",
    "    .drop(household_df.REPORT_DATE).limit(30000)\n",
    "ibro_verint_df=ibro_verint_df1.union(ibro_verint_df3)\n",
    "ibro_verint_df=ibro_verint_df.union(ibro_verint_df2)\n",
    "## moving .drop(verint.account_number) because no such column\n",
    "print(\"=======================merged ibro and verint===============================\")\n",
    "print(ibro_verint_df.columns)\n",
    "print(\"ibro_verint count rows: {}\".format(ibro_verint_df.count()))\n",
    "\n",
    "# verint_etl = VerintETL(verint)\n",
    "\n",
    "verint_etl = VerintETL(ibro_verint_df) \n",
    "verint_df = verint_etl.cbl_ser_etl_spark() # preprocess\n",
    "train_final_df = verint_etl.en_product_mention_etl(verint_df) # 3. merge as transformation\n",
    "\n",
    "train_temp_path=\"dbfs:/mnt/ml-model-output-scores-data/mlmodel_output/digital/CD4MT/Verint/GLDA_Topic_Modelling_Output/Connected_Home/cancel_and_move_bertopic_training\"\n",
    "train_final_df.write.mode(\"overwrite\").option(\"header\", True).parquet(train_temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8db342c-5a90-46e6-9e38-0f7ea91a8b8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_temp_path=\"dbfs:/mnt/ml-model-output-scores-data/mlmodel_output/digital/CD4MT/Verint/GLDA_Topic_Modelling_Output/Connected_Home/cancel_and_move_bertopic_training\"\n",
    "train_final_df=spark.read.parquet(train_temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ec28e7a-550a-4682-8e75-9fd19ebc56e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Generate evaluation metrics for Guided-LDA model on testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "027baad1-f9ee-4b76-a6b9-20e7a6c8685e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 3976\nTN count: 291638\nFP count: 2733\nFN count: 63367\nPrecision: 0.5926367565956179\nRecall: 0.05904102876319736\nAccuracy: 0.8172589393830485\n"
     ]
    }
   ],
   "source": [
    "#17 topics (inlcude miscelluous) from GLDA\n",
    "#top 1 calculation : precision, recall, accuracy \n",
    "tp_cancel = comparsion_df.filter((col(\"cancel\") == True)).filter(col(\"top_topic\") == \"Deactivation\").count()\n",
    "print(f\"TP count: {tp_cancel}\")\n",
    "\n",
    "tn_cancel = comparsion_df.filter((col(\"cancel\") == False) ).filter(col(\"top_topic\") != \"Deactivation\").count()\n",
    "print(f\"TN count: {tn_cancel}\")\n",
    "\n",
    "fp_cancel = comparsion_df.filter((col(\"cancel\") == False)).filter(col(\"top_topic\") == \"Deactivation\").count()\n",
    "print(f\"FP count: {fp_cancel}\")\n",
    "\n",
    "fn_cancel = comparsion_df.filter((col(\"cancel\") == True)).filter(col(\"top_topic\") != \"Deactivation\").count()\n",
    "print(f\"FN count: {fn_cancel}\")\n",
    "\n",
    "precision_cancel = tp_cancel / (tp_cancel + fp_cancel)\n",
    "print(f\"Precision: {precision_cancel}\")\n",
    "\n",
    "recall_cancel = tp_cancel / (tp_cancel + fn_cancel)\n",
    "print(f\"Recall: {recall_cancel}\")\n",
    "Accuracy = (tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel) \n",
    "print(f\"Accuracy: {(tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel)}\")\n",
    "\n",
    "cancel = [('cancel', tp_cancel, tn_cancel, fp_cancel, fn_cancel, precision_cancel, recall_cancel, Accuracy)]\n",
    "f1 = spark.createDataFrame(data=cancel, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])\n",
    "f1.createOrReplaceTempView(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b38d21e-1af2-41e4-940c-fe519a9a01f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 5522\nTN count: 256795\nFP count: 3944\nFN count: 95453\nPrecision: 0.5833509402070568\nRecall: 0.05468680366427334\nAccuracy: 0.7252055491355048\n"
     ]
    }
   ],
   "source": [
    "tp_moves = comparsion_df.filter((col(\"move\") == True) ).filter(col(\"top_topic\") == \"Move Request\").count()\n",
    "print(f\"TP count: {tp_moves}\")\n",
    "\n",
    "tn_moves = comparsion_df.filter((col(\"move\") == False)).filter(col(\"top_topic\") != \"Move Request\").count()\n",
    "print(f\"TN count: {tn_moves}\")\n",
    "\n",
    "fp_moves = comparsion_df.filter((col(\"move\") == False)).filter(col(\"top_topic\") == \"Move Request\").count()\n",
    "print(f\"FP count: {fp_moves}\")\n",
    "\n",
    "fn_moves = comparsion_df.filter((col(\"move\") == True)).filter(col(\"top_topic\") != \"Move Request\").count()\n",
    "print(f\"FN count: {fn_moves}\")\n",
    "\n",
    "precision_moves = tp_moves / (tp_moves + fp_moves)\n",
    "print(f\"Precision: {precision_moves}\")\n",
    "Accuracy = (tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)\n",
    "recall_moves = tp_moves / (tp_moves + fn_moves)\n",
    "print(f\"Recall: {recall_moves}\")\n",
    "print(f\"Accuracy: {(tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)}\")\n",
    "\n",
    "move = [('moves', tp_moves, tn_moves, fp_moves, fn_moves, precision_moves, recall_moves, Accuracy)]\n",
    "f2 = spark.createDataFrame(data=move, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a119f787-7c41-4c88-afe7-cf8937f7aa72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 14421\nTN count: 294371\nFP count: 13189\nFN count: 67343\nPrecision: 0.5223107569721116\nRecall: 0.1763734650946627\nAccuracy: 0.7931491508358077\n"
     ]
    }
   ],
   "source": [
    "#top 3 calculation : precision, recall, accuracy \n",
    "tp_cancel = comparsion_df.filter((col(\"cancel\") == True)).filter((col(\"top_topic\") == \"Deactivation\") | (col(\"2nd_topic\") == \"Deactivation\") | (col(\"3rd_topic\") == \"Deactivation\") ).count()\n",
    "print(f\"TP count: {tp_cancel}\")\n",
    "\n",
    "tn_cancel = comparsion_df.filter((col(\"cancel\") == False)).filter((col(\"top_topic\") != \"Deactivation\") | (col(\"2nd_topic\") != \"Deactivation\") | (col(\"3rd_topic\") != \"Deactivation\") ).count()\n",
    "print(f\"TN count: {tn_cancel}\")\n",
    "\n",
    "fp_cancel = comparsion_df.filter((col(\"cancel\") == False) ).filter((col(\"top_topic\") == \"Deactivation\") | (col(\"2nd_topic\") == \"Deactivation\") | (col(\"3rd_topic\") == \"Deactivation\") ).count()\n",
    "print(f\"FP count: {fp_cancel}\")\n",
    "\n",
    "fn_cancel = comparsion_df.filter((col(\"cancel\") == True) ).filter((col(\"top_topic\") != \"Deactivation\") | (col(\"2nd_topic\") != \"Deactivation\") | (col(\"3rd_topic\") != \"Deactivation\") ).count()\n",
    "print(f\"FN count: {fn_cancel}\")\n",
    "\n",
    "precision_cancel = tp_cancel / (tp_cancel + fp_cancel)\n",
    "print(f\"Precision: {precision_cancel}\")\n",
    "\n",
    "recall_cancel = tp_cancel / (tp_cancel + fn_cancel)\n",
    "print(f\"Recall: {recall_cancel}\")\n",
    "Accuracy = (tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel) \n",
    "print(f\"Accuracy: {(tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel)}\")\n",
    "\n",
    "cancel = [('cancel', tp_cancel, tn_cancel, fp_cancel, fn_cancel, precision_cancel, recall_cancel, Accuracy)]\n",
    "f5 = spark.createDataFrame(data=cancel, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])\n",
    "f5.createOrReplaceTempView(\"f5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97c05a62-9f56-435e-9e41-d02fe5c53f3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 18824\nTN count: 260739\nFP count: 22810\nFN count: 100975\nPrecision: 0.45213047028870634\nRecall: 0.1571298591807945\nAccuracy: 0.6931062010968196\n"
     ]
    }
   ],
   "source": [
    "tp_moves = comparsion_df.filter((col(\"move\") == True) ).filter((col(\"top_topic\") == \"Move Request\") | (col(\"2nd_topic\") == \"Move Request\") | (col(\"3rd_topic\") == \"Move Request\") ).count()\n",
    "print(f\"TP count: {tp_moves}\")\n",
    "\n",
    "tn_moves = comparsion_df.filter((col(\"move\") == False) ).filter((col(\"top_topic\") != \"Move Request\") | (col(\"2nd_topic\") != \"Move Request\") | (col(\"3rd_topic\") != \"Move Request\") ).count()\n",
    "print(f\"TN count: {tn_moves}\")\n",
    "\n",
    "fp_moves = comparsion_df.filter((col(\"move\") == False)).filter((col(\"top_topic\") == \"Move Request\") | (col(\"2nd_topic\") == \"Move Request\") | (col(\"3rd_topic\") == \"Move Request\") ).count()\n",
    "print(f\"FP count: {fp_moves}\")\n",
    "\n",
    "fn_moves = comparsion_df.filter((col(\"move\") == True) ).filter((col(\"top_topic\") != \"Move Request\") | (col(\"2nd_topic\") != \"Move Request\") | (col(\"3rd_topic\") != \"Move Request\") ).count()\n",
    "print(f\"FN count: {fn_moves}\")\n",
    "\n",
    "precision_moves = tp_moves / (tp_moves + fp_moves)\n",
    "print(f\"Precision: {precision_moves}\")\n",
    "Accuracy = (tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)\n",
    "recall_moves = tp_moves / (tp_moves + fn_moves)\n",
    "print(f\"Recall: {recall_moves}\")\n",
    "print(f\"Accuracy: {(tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)}\")\n",
    "\n",
    "move = [('moves', tp_moves, tn_moves, fp_moves, fn_moves, precision_moves, recall_moves, Accuracy)]\n",
    "f6 = spark.createDataFrame(data=move, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b17e96d-901b-4ea5-96cd-08d322c84c11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 24041\nTN count: 294371\nFP count: 29674\nFN count: 67343\nPrecision: 0.44756585683701017\nRecall: 0.26307668738510026\nAccuracy: 0.7664655091483743\n"
     ]
    }
   ],
   "source": [
    "#top 5 calculation : precision, recall, accuracy\n",
    "tp_cancel = comparsion_df.filter((col(\"cancel\") == True) ).filter((col(\"top_topic\") == \"Deactivation\") | (col(\"2nd_topic\") == \"Deactivation\") | (col(\"3rd_topic\") == \"Deactivation\") | (col(\"4th_topic\") == \"Deactivation\") | (col(\"5th_topic\") == \"Deactivation\")).count()\n",
    "print(f\"TP count: {tp_cancel}\")\n",
    "\n",
    "tn_cancel = comparsion_df.filter((col(\"cancel\") == False) ).filter((col(\"top_topic\") != \"Deactivation\") | (col(\"2nd_topic\") != \"Deactivation\") | (col(\"3rd_topic\") != \"Deactivation\") | (col(\"4th_topic\") != \"Deactivation\") | (col(\"5th_topic\") != \"Deactivation\")).count()\n",
    "print(f\"TN count: {tn_cancel}\")\n",
    "\n",
    "fp_cancel = comparsion_df.filter((col(\"cancel\") == False) ).filter((col(\"top_topic\") == \"Deactivation\") | (col(\"2nd_topic\") == \"Deactivation\") | (col(\"3rd_topic\") == \"Deactivation\") | (col(\"4th_topic\") == \"Deactivation\") | (col(\"5th_topic\") == \"Deactivation\")).count()\n",
    "print(f\"FP count: {fp_cancel}\")\n",
    "\n",
    "fn_cancel = comparsion_df.filter((col(\"cancel\") == True)).filter((col(\"top_topic\") != \"Deactivation\") | (col(\"2nd_topic\") != \"Deactivation\") | (col(\"3rd_topic\") != \"Deactivation\") | (col(\"4th_topic\") != \"Deactivation\") | (col(\"5th_topic\") != \"Deactivation\")).count()\n",
    "print(f\"FN count: {fn_cancel}\")\n",
    "\n",
    "precision_cancel = tp_cancel / (tp_cancel + fp_cancel)\n",
    "print(f\"Precision: {precision_cancel}\")\n",
    "\n",
    "recall_cancel = tp_cancel / (tp_cancel + fn_cancel)\n",
    "print(f\"Recall: {recall_cancel}\")\n",
    "Accuracy = (tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel) \n",
    "print(f\"Accuracy: {(tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel)}\")\n",
    "\n",
    "cancel = [('cancel', tp_cancel, tn_cancel, fp_cancel, fn_cancel, precision_cancel, recall_cancel, Accuracy)]\n",
    "f = spark.createDataFrame(data=cancel, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])\n",
    "f.createOrReplaceTempView(\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "365c4f27-c33c-498a-842c-e22314f1cfc0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 32372\nTN count: 260739\nFP count: 51237\nFN count: 100975\nPrecision: 0.3871831979810786\nRecall: 0.242765116575551\nAccuracy: 0.6581986558071332\n"
     ]
    }
   ],
   "source": [
    "tp_moves = comparsion_df.filter((col(\"move\") == True) ).filter((col(\"top_topic\") == \"Move Request\") | (col(\"2nd_topic\") == \"Move Request\") | (col(\"3rd_topic\") == \"Move Request\") | (col(\"4th_topic\") == \"Move Request\") | (col(\"5th_topic\") == \"Move Request\")).count()\n",
    "print(f\"TP count: {tp_moves}\")\n",
    "\n",
    "tn_moves = comparsion_df.filter((col(\"move\") == False) ).filter((col(\"top_topic\") != \"Move Request\") | (col(\"2nd_topic\") != \"Move Request\") | (col(\"3rd_topic\") != \"Move Request\") | (col(\"4th_topic\") != \"Move Request\") | (col(\"5th_topic\") != \"Move Request\")).count()\n",
    "print(f\"TN count: {tn_moves}\")\n",
    "\n",
    "fp_moves = comparsion_df.filter((col(\"move\") == False) ).filter((col(\"top_topic\") == \"Move Request\") | (col(\"2nd_topic\") == \"Move Request\") | (col(\"3rd_topic\") == \"Move Request\") | (col(\"4th_topic\") == \"Move Request\") | (col(\"5th_topic\") == \"Move Request\")).count()\n",
    "print(f\"FP count: {fp_moves}\")\n",
    "\n",
    "fn_moves = comparsion_df.filter((col(\"move\") == True) ).filter((col(\"top_topic\") != \"Move Request\") | (col(\"2nd_topic\") != \"Move Request\") | (col(\"3rd_topic\") != \"Move Request\") | (col(\"4th_topic\") != \"Move Request\") | (col(\"5th_topic\") != \"Move Request\")).count()\n",
    "print(f\"FN count: {fn_moves}\")\n",
    "\n",
    "precision_moves = tp_moves / (tp_moves + fp_moves)\n",
    "print(f\"Precision: {precision_moves}\")\n",
    "Accuracy = (tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)\n",
    "recall_moves = tp_moves / (tp_moves + fn_moves)\n",
    "print(f\"Recall: {recall_moves}\")\n",
    "print(f\"Accuracy: {(tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)}\")\n",
    "\n",
    "move = [('moves', tp_moves, tn_moves, fp_moves, fn_moves, precision_moves, recall_moves, Accuracy)]\n",
    "f3 = spark.createDataFrame(data=move, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0e504f1-81b9-47e8-9d29-efa6c3f25ea0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[33]: DataFrame[SPEECH_ID_VERINT: string, TEXT_CUSTOMER_FULL: string, TEXT_AGENT_FULL: string, TEXT_ALL: string, RECEIVING_SKILL: string, CTN: string, CUSTOMER_ID: string, CONVERSATION_DATE: date, Year: int, Month: int, CONNECTION_ID: string, CLEAN_TEXT_CUSTOMER: string, CLEAN_TEXT_AGENT: string, COMPETITOR_MENTION: string, ROGERS_FIDO_MENTION: string, PRODUCT_MENTION: string, top_topic: string, 2nd_topic: string, 3rd_topic: string, 4th_topic: string, 5th_topic: string, lda_inference_result: array<double>, cancel: boolean, move: boolean, cancel_mention: boolean, move_mention: boolean]"
     ]
    }
   ],
   "source": [
    "comparsion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89194afa-8720-4aa2-a663-f0a25f825063",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#only label for cancel / for move\n",
    "comparsion_df_pd=comparsion_df.select([\"SPEECH_ID_VERINT\",\"TEXT_CUSTOMER_FULL\",\"CLEAN_TEXT_CUSTOMER\",\"cancel\",\"move\",\"cancel_mention\",\"move_mention\"]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "139e9917-ac16-4410-b2a0-c461329c4cac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SPEECH_ID_VERINT</th>\n      <th>TEXT_CUSTOMER_FULL</th>\n      <th>CLEAN_TEXT_CUSTOMER</th>\n      <th>cancel</th>\n      <th>move</th>\n      <th>cancel_mention</th>\n      <th>move_mention</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>504040085168657</td>\n      <td>SO LITTLE BIT HARD TO, RENTED YOUR AND A VAN O...</td>\n      <td>bit hard rent van channel year flight pre purc...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>504026085339031</td>\n      <td>OKAY I'M JUST WONDERING, I RECEIVE MY BILL WHY...</td>\n      <td>receive bill bill high walk term month bill us...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>504060086115429</td>\n      <td>WHAT'S NOT DIDN'T DO IT UP, OKAY, MY BILL IT G...</td>\n      <td>bill go know wait eva bit leave team change av...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>504028086101940</td>\n      <td>GOOD MORNING THIS IS RINA FROM ROGERS HOW CAN ...</td>\n      <td>rina rogers get save bill change postal code i...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>504060087279166</td>\n      <td>LOUIS, GIVE CALLING I HAVE NO ALONE ENTER THAT...</td>\n      <td>louis call enter ignite tv elia restore minute...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>361709</th>\n      <td>504050086626925</td>\n      <td>HI MY NAME IS FROM YOUR FROM OUR NUMBER PROPER...</td>\n      <td>number property manager avenue road get new co...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>361710</th>\n      <td>504062085795792</td>\n      <td>MY MY INTERNET NO NO WIRELESS AND THEN I DON'T...</td>\n      <td>internet wireless know line low internet get c...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>361711</th>\n      <td>504048085081139</td>\n      <td>I HAVE A PROBLEM, BY BOX, SAYS SORRY OR CABLE ...</td>\n      <td>problem box say cable box button work call num...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>361712</th>\n      <td>504034086911591</td>\n      <td>YEAH EIGHT BOX, I JUST WANT TO KNOW HOW MUCH M...</td>\n      <td>box know account number monthly bill prepay bi...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>361713</th>\n      <td>504072084872523</td>\n      <td>CALCULATE OKAY, MY HOME PHONE IS NOT WORKING I...</td>\n      <td>calculate home phone work say line cable wait ...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>361714 rows × 7 columns</p>\n</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SPEECH_ID_VERINT</th>\n      <th>TEXT_CUSTOMER_FULL</th>\n      <th>CLEAN_TEXT_CUSTOMER</th>\n      <th>cancel</th>\n      <th>move</th>\n      <th>cancel_mention</th>\n      <th>move_mention</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>504040085168657</td>\n      <td>SO LITTLE BIT HARD TO, RENTED YOUR AND A VAN O...</td>\n      <td>bit hard rent van channel year flight pre purc...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>504026085339031</td>\n      <td>OKAY I'M JUST WONDERING, I RECEIVE MY BILL WHY...</td>\n      <td>receive bill bill high walk term month bill us...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>504060086115429</td>\n      <td>WHAT'S NOT DIDN'T DO IT UP, OKAY, MY BILL IT G...</td>\n      <td>bill go know wait eva bit leave team change av...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>504028086101940</td>\n      <td>GOOD MORNING THIS IS RINA FROM ROGERS HOW CAN ...</td>\n      <td>rina rogers get save bill change postal code i...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>504060087279166</td>\n      <td>LOUIS, GIVE CALLING I HAVE NO ALONE ENTER THAT...</td>\n      <td>louis call enter ignite tv elia restore minute...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>361709</th>\n      <td>504050086626925</td>\n      <td>HI MY NAME IS FROM YOUR FROM OUR NUMBER PROPER...</td>\n      <td>number property manager avenue road get new co...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>361710</th>\n      <td>504062085795792</td>\n      <td>MY MY INTERNET NO NO WIRELESS AND THEN I DON'T...</td>\n      <td>internet wireless know line low internet get c...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>361711</th>\n      <td>504048085081139</td>\n      <td>I HAVE A PROBLEM, BY BOX, SAYS SORRY OR CABLE ...</td>\n      <td>problem box say cable box button work call num...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>361712</th>\n      <td>504034086911591</td>\n      <td>YEAH EIGHT BOX, I JUST WANT TO KNOW HOW MUCH M...</td>\n      <td>box know account number monthly bill prepay bi...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>361713</th>\n      <td>504072084872523</td>\n      <td>CALCULATE OKAY, MY HOME PHONE IS NOT WORKING I...</td>\n      <td>calculate home phone work say line cable wait ...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>361714 rows × 7 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparsion_df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f201959-2ba8-45e7-9f97-bea96f009740",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_final_df_pd=train_final_df.select([\"SPEECH_ID_VERINT\",\"CLEAN_TEXT_CUSTOMER\",\"TEXT_CUSTOMER_FULL\"]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a681612-3bc0-45d8-b424-777c74503c77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SPEECH_ID_VERINT</th>\n      <th>CLEAN_TEXT_CUSTOMER</th>\n      <th>TEXT_CUSTOMER_FULL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>504034068351565</td>\n      <td>ahead frustrate get direction smart home monit...</td>\n      <td>AHEAD, THANK YOU THANK YOU, FINE I'M JUST VERY...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>504030066153475</td>\n      <td>account online confirm special arrangement que...</td>\n      <td>THANK YOU, I'M LOOKING AT MY ACCOUNT ONLINE AN...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>504030066727042</td>\n      <td>question pay end month say hold get limit know...</td>\n      <td>YES MY NAME IS, QUESTION IS, YOU ARE YOU HELP ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>504064067040979</td>\n      <td>national call phone number</td>\n      <td>HI MY NAME IS HER NATIONAL,  EIGHT EIGHT FORTY...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>504032065162553</td>\n      <td>awesome extension number id number rate cancel...</td>\n      <td>HERE I JUST GIVE ME YOUR NAME, I, HERE YOUR LA...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>138078</th>\n      <td>504028077386450</td>\n      <td>get phone year rebate nothings work provide ch...</td>\n      <td>WELL WE NEED I NEED SOMEONE I HERE THERE LIKE ...</td>\n    </tr>\n    <tr>\n      <th>138079</th>\n      <td>504028077069451</td>\n      <td>speak rogers come television lick reason numbe...</td>\n      <td>I WAS JUST SPEAKING TO SOMEONE FROM ROGERS THE...</td>\n    </tr>\n    <tr>\n      <th>138080</th>\n      <td>504058067758651</td>\n      <td>call debbie income call click card oclock walk...</td>\n      <td>YEAH I'M CALLING TO DEBBIE MONEY INCOMING I I ...</td>\n    </tr>\n    <tr>\n      <th>138081</th>\n      <td>504068064869794</td>\n      <td>high month corporate charlie telephone number ...</td>\n      <td>HIGH LET ME SEE, MY NAME IS DONE DAYS THE MY W...</td>\n    </tr>\n    <tr>\n      <th>138082</th>\n      <td>504046064964724</td>\n      <td>rachel hauler action quality rainy miss miss p...</td>\n      <td>RACHEL HAULER, YEAH ACTIONS QUALITY IT RAINY T...</td>\n    </tr>\n  </tbody>\n</table>\n<p>138083 rows × 3 columns</p>\n</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SPEECH_ID_VERINT</th>\n      <th>CLEAN_TEXT_CUSTOMER</th>\n      <th>TEXT_CUSTOMER_FULL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>504034068351565</td>\n      <td>ahead frustrate get direction smart home monit...</td>\n      <td>AHEAD, THANK YOU THANK YOU, FINE I'M JUST VERY...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>504030066153475</td>\n      <td>account online confirm special arrangement que...</td>\n      <td>THANK YOU, I'M LOOKING AT MY ACCOUNT ONLINE AN...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>504030066727042</td>\n      <td>question pay end month say hold get limit know...</td>\n      <td>YES MY NAME IS, QUESTION IS, YOU ARE YOU HELP ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>504064067040979</td>\n      <td>national call phone number</td>\n      <td>HI MY NAME IS HER NATIONAL,  EIGHT EIGHT FORTY...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>504032065162553</td>\n      <td>awesome extension number id number rate cancel...</td>\n      <td>HERE I JUST GIVE ME YOUR NAME, I, HERE YOUR LA...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>138078</th>\n      <td>504028077386450</td>\n      <td>get phone year rebate nothings work provide ch...</td>\n      <td>WELL WE NEED I NEED SOMEONE I HERE THERE LIKE ...</td>\n    </tr>\n    <tr>\n      <th>138079</th>\n      <td>504028077069451</td>\n      <td>speak rogers come television lick reason numbe...</td>\n      <td>I WAS JUST SPEAKING TO SOMEONE FROM ROGERS THE...</td>\n    </tr>\n    <tr>\n      <th>138080</th>\n      <td>504058067758651</td>\n      <td>call debbie income call click card oclock walk...</td>\n      <td>YEAH I'M CALLING TO DEBBIE MONEY INCOMING I I ...</td>\n    </tr>\n    <tr>\n      <th>138081</th>\n      <td>504068064869794</td>\n      <td>high month corporate charlie telephone number ...</td>\n      <td>HIGH LET ME SEE, MY NAME IS DONE DAYS THE MY W...</td>\n    </tr>\n    <tr>\n      <th>138082</th>\n      <td>504046064964724</td>\n      <td>rachel hauler action quality rainy miss miss p...</td>\n      <td>RACHEL HAULER, YEAH ACTIONS QUALITY IT RAINY T...</td>\n    </tr>\n  </tbody>\n</table>\n<p>138083 rows × 3 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_final_df_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15f159ac-be67-4b82-8d1b-6ee70e7df4cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Modeling using guided version of bertopic:    \n",
    "### Guided means a list of anchor topics and words corresponding to each of the topic are provided to the model, since customized instead of random topics are wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c46f9a72-b0d1-4107-8661-1f016a549218",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306e3b5b6da74f3191e64fa1e2b10c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Batches:   0%|          | 0/4316 [00:00<?, ?it/s]"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "306e3b5b6da74f3191e64fa1e2b10c62",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Batches:   0%|          | 0/4316 [00:00<?, ?it/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "d4426be0-9175b1c73a5e5666e0f9edec"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 20:48:41,730 - BERTopic - Transformed documents to Embeddings\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a206be05c74602bfebcd884f0983af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "87a206be05c74602bfebcd884f0983af",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "d4426be0-9175b1c73a5e5666e0f9edec"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 20:50:13,259 - BERTopic - Reduced dimensionality\n2023-03-15 20:52:09,587 - BERTopic - Clustered reduced embeddings\n2023-03-15 20:59:49,148 - BERTopic - Reduced number of topics from 126 to 30\n"
     ]
    }
   ],
   "source": [
    "#guided bertopic on raw conversation\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "#guided version has seed_topic_list\n",
    "\n",
    "\n",
    "seed_topic_list = [\n",
    "    #promotion inquiry\n",
    "    ['internet promo', 'set expire', 'come end', 'expire month', 'promotion expire', 'promotion internet', \n",
    "    'offer available', 'offer end offer', 'internet promotion end', 'internet plan expire',\n",
    "    'internet promotion expire', 'plan expire', 'offer deal', 'loyal customer', 'promotion expire soon', \n",
    "    'know promotion', 'internet promo end', 'internet promotion', 'price internet', 'soon offer', \n",
    "    'expire soon offer', 'new promotion', 'promo end'], \n",
    "\n",
    "    #billing inquiry \n",
    "    ['charge month', 'charge late payment', 'late payment charge', 'high month', 'charge late', \n",
    "    'month home', 'pay time', 'cycle end', 'late payment', 'new monthly', 'billing billing', \n",
    "    'say bill', 'bill bill', 'bill increase', 'bill go', 'monthly bill', 'increase bill', \n",
    "    'internet bill', 'account balance', 'bill high', 'bill issue', 'current bill', 'overage charge',\n",
    "    'bill inquiry'],\n",
    "\n",
    "    #cancel\n",
    "    ['cancel','cancellation','cancel service', 'account cancel', 'account cancel account', 'account return', 'address cancel', \n",
    "     'canada post', 'cancel account', 'cancel cable', 'cancel cancel', 'cancel cause', 'cancel charge',\n",
    "     'cancel credit', 'cancel home','cancel home phone','cancel internet', 'cancel internet service', \n",
    "     'cancel month', 'cancel pay', 'cancel phone', 'cancel return', 'cancel service', 'cancel service cancel',\n",
    "     'close account','cancel time', 'cause cancel', 'credit cancel', 'end month', 'home monitoring','home monitor',\n",
    "     'internet cancel', 'modem cancel', 'month cancel', 'new account' ,'pay cancel', 'pay return', 'phone cancel', \n",
    "     'return account', 'service cancel','service return', 'store return','time cancel', 'time return','cancel rogers', \n",
    "     'rogers cancel', 'account cancelation', 'cancel plan', 'canceling service','question cancel', 'service end month',\n",
    "     'internet service cancel', 'cancel internet cancel','anymore cancel','cancel home internet','service cancel internet',\n",
    "     'service cancel service', 'cancel subscription', 'cancel tv','internet cancel internet'\n",
    "    ],\n",
    "\n",
    "    #Plan Inquiry - Internet\n",
    "    ['option account', 'deal internet', 'plan home internet', 'internet ignite', 'cost upgrade', \n",
    "    'change internet plan', 'change internet package', 'question upgrade', 'change plan change', \n",
    "    'internet unlimited', 'internet plan change', 'data usage', 'new plan', 'internet time', \n",
    "    'roger internet', 'internet deal', 'upgrade internet speed', 'internet package', 'plan home', \n",
    "    'home internet plan', 'internet internet', 'home internet'],\n",
    "\n",
    "    #myrogers\n",
    "    ['rogers online', 'password rogers', 'telecommunication service view', 'message able', \n",
    "    'display info', 'online message', 'say able display', 'account number register', \n",
    "    'manage company telecommunication', 'work fix', 'online message able', 'telecommunication service',\n",
    "    'manage company', 'reset voicemail', 'fix able display', 'service view', 'number register',\n",
    "    'password rogers online', 'company telecommunication', 'able display', 'fix issue', 'fix able',\n",
    "    'reset voicemail password', 'rogers online message'],\n",
    "\n",
    "    #bundle inquiry\n",
    "    ['tv internet phone', 'phone tv', 'tv bundle', 'bundle tv internet', 'ignite bundle', \n",
    "    'change flex', 'ignite premier', 'internet home phone', 'ignite popular', 'ignite popular bundle',\n",
    "    'bundle ignite', 'popular bundle', 'phone bundle', 'home phone tv', 'channel flex', 'bundle tv', \n",
    "    'channel flex channel', 'change flex channel', 'internet phone', 'ignite tv bundle'],\n",
    "\n",
    "    #equipment inquiry\n",
    "    ['modem return', 'modem send', 'modem tell', 'charge return', 'send return', 'return cable box',\n",
    "    'tell send', 'return label', 'store open', 'receive label', 'equipment return', 'wait return',\n",
    "    'return cable', 'equipment equipment', 'box return', 'label rogers', 'internet modem', 'return old', \n",
    "    'confirm receive', 'ship label', 'service address', 'modem store', 'return modem', 'return equipment', \n",
    "    'label rogers send'],\n",
    "\n",
    "    #Tech Support\n",
    "    ['new modem work', 'issue time', 'status provide', 'box status', 'serial number check', \n",
    "    'provide serial', 'number check', 'provide serial number', 'speed slow', 'work internet', \n",
    "    'area internet', 'modem work', 'internet work internet', 'internet connection', \n",
    "    'provide serial', 'phone work', 'internet issue'],\n",
    "\n",
    "    #technician installation inquiry\n",
    "    ['come way', 'receive text', 'come rogers', 'reschedule appointment', 'number tell', \n",
    "    'technician come', 'install internet', 'technician install', 'cancel installation', \n",
    "    'installation date'],\n",
    "\n",
    "    #tv addon inuqiry\n",
    "    ['add channel add', 'theme pack', 'crave tv', 'tv rogers', 'channel tv', 'nfl ticket', \n",
    "    'channel tv package', 'add channel', 'channel add channel', 'rogers nhl'],\n",
    "\n",
    "    #plan inquiry tv\n",
    "    ['package change package', 'tv package popular', 'package package', 'change package', \n",
    "    'package popular'],\n",
    "\n",
    "    #payment inquiry\n",
    "    ['charge pay', 'payment payment', 'credit card info', 'pay internet', 'card info', \n",
    "    'payment online', 'change payment', 'pay bill', 'payment arrangement', 'internet pay'],\n",
    "\n",
    "    #account inquiry\n",
    "    ['number change', 'number link', 'set myroger account', 'account change', 'number end', \n",
    "    'place order', 'account number set', 'number account', 'old account', 'line new', 'change phone',\n",
    "    'number set', 'receive service', 'link account', 'line change', 'change service', 'internet usage',\n",
    "    'rogers account'],\n",
    "\n",
    "    #plan inquiry home phone\n",
    "    ['standard long distance', 'distance charge', 'distance plan', 'long distance phone', \n",
    "    'distance phone', 'long distance plan', 'long distance', 'long distance charge', 'home phone', \n",
    "    'phone plan', 'standard long'],\n",
    "\n",
    "    #moves\n",
    "    ['address','move','moving','new address','old address','address address','address account','change address','account address', \n",
    "     'address send', 'address new', 'account new','new place','service address', 'new work','change job', \n",
    "     'send address', 'new house', 'address change', 'service new','technical support' ,'tech support' ,\n",
    "     'send technician','home address','new service', 'address cause', 'current address', \n",
    "     'set account', 'address file','new account' ,'home internet', 'address internet', 'set address', \n",
    "     'address phone', 'toronto ontario', 'address service','work home' ,'new modem',\n",
    "     'set new' ,'transfer service','address old', 'internet new', 'new new', 'new home', 'new job',\n",
    "     'mailing address','mail address', 'address check', 'send new', 'new location', 'address long', 'address new address',\n",
    "     'previous address', 'new apartment','internet service','cause address', 'address pay', 'check address', \n",
    "     'brand new', 'sell house', 'address home', 'address street', 'modem new',\n",
    "     'send check', 'house house', 'address cancel', 'address location', 'address relocate', 'account relocate',\n",
    "     'location relocate', 'change address','new house', 'new condo', 'new apartment', 'new place',\n",
    "     'new city', 'new province', 'moving in','move in','leaving home','service area', 'leave home', \n",
    "     'moving back','move back', 'moving out','move out', 'old place','new address new','service new address',\n",
    "     'service hold', 'transfer service new', \n",
    "     'move new', 'moving new', 'move place', 'moving place', 'move address', 'moving address'\n",
    "     ],\n",
    "\n",
    "     #customer notification\n",
    "    ['safe sign internet', 'safe sign', 'sign internet', 'email state', 'email receive email', \n",
    "    'email rogers', 'sign internet service', 'service limited', 'stay safe sign', \n",
    "    'automatically apply']\n",
    "\n",
    "] \n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 3))#stop words already removed at preprocessing, no need to do it again\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# Step 6 - (Optional) Fine-tune topic representations with \n",
    "# a `bertopic.representation` model\n",
    "representation_model = KeyBERTInspired()\n",
    "\n",
    "# All steps together\n",
    "guided_topic_model_processed = BERTopic(\n",
    "  #min_topic_size=100,\n",
    "  nr_topics=30, #customize cluster size to 30, otherwise would get hundreds\n",
    "  language=\"english\", \n",
    "  calculate_probabilities=True,\n",
    "  top_n_words=20, \n",
    "  n_gram_range=(1, 3), #most of the phrases and words we want to capture are bigrams, a few are unigrams and trigrams\n",
    "  verbose=True,\n",
    "  seed_topic_list=seed_topic_list,\n",
    "  embedding_model=embedding_model,          # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,                    # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,              # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,        # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,                # Step 5 - Extract topic words\n",
    "  representation_model=representation_model # Step 6 - (Optional) Fine-tune topic represenations\n",
    ")\n",
    "\n",
    "guided_topics_processed, guided_probs_processed = guided_topic_model_processed.fit_transform(train_final_df_pd[\"CLEAN_TEXT_CUSTOMER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de80e891-158e-4b50-b0c8-252c6db02bd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topic</th>\n      <th>Count</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>104269</td>\n      <td>-1_cell phone_home phone_customer_service</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>7255</td>\n      <td>0_remote control_tv box_get channel_turn tv</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6002</td>\n      <td>1_modem_new modem_internet connection_router</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>3769</td>\n      <td>2_bill pay_pay bill_get bill_bill month</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>2979</td>\n      <td>3_cancel service_cancel internet service_servi...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4</td>\n      <td>2163</td>\n      <td>4_street_line_bill_customer</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5</td>\n      <td>2091</td>\n      <td>5_move address_move new address_call move_move...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6</td>\n      <td>1658</td>\n      <td>6_password rogers_password say_password get_pa...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7</td>\n      <td>1443</td>\n      <td>7_call maam_maam call_maam_maam maam</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8</td>\n      <td>1102</td>\n      <td>8_call behalf mother_fathers account_mothers a...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9</td>\n      <td>1028</td>\n      <td>9_appointment cancel_cancel appointment_schedu...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10</td>\n      <td>1008</td>\n      <td>10_rogers email_email get_emails_mailbox</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>11</td>\n      <td>864</td>\n      <td>11_get ignite_ignite tv_rogers ignite_say ignite</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>12</td>\n      <td>739</td>\n      <td>12_cancel home monitor_smart home monitor_home...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>13</td>\n      <td>615</td>\n      <td>13_postal code_code postal code_postal code ge...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>14</td>\n      <td>224</td>\n      <td>14_technician call_call technician_technician ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>15</td>\n      <td>166</td>\n      <td>15_call cancel fido_cancel fido internet_fido ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>16</td>\n      <td>156</td>\n      <td>16_internet promotion_promotion internet_promo...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>17</td>\n      <td>100</td>\n      <td>17_disney subscription_get disney_disney get_d...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>18</td>\n      <td>67</td>\n      <td>18_mohammed cancel service_mohammed account_pa...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>19</td>\n      <td>66</td>\n      <td>19_call get disconnect_call disconnect_get dis...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>20</td>\n      <td>64</td>\n      <td>20_call month_phone month_end month_month call</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>21</td>\n      <td>50</td>\n      <td>21_suspend month_suspend bill_suspend service_...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>22</td>\n      <td>46</td>\n      <td>22_fiber service_fiber internet_phone internet...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>23</td>\n      <td>40</td>\n      <td>23_ipad get_get ipad_ipad go_ipad</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>24</td>\n      <td>38</td>\n      <td>24_get speak french_speak french_speak french ...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>25</td>\n      <td>26</td>\n      <td>25_printer internet_work printer_printer get_p...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>26</td>\n      <td>22</td>\n      <td>26_phone line fax_fax call_phone fax_fax line ...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>27</td>\n      <td>18</td>\n      <td>27_call oclock_get oclock_know oclock open_ocl...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>28</td>\n      <td>15</td>\n      <td>28_address service_mustve cancel email_kevin s...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topic</th>\n      <th>Count</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>104269</td>\n      <td>-1_cell phone_home phone_customer_service</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>7255</td>\n      <td>0_remote control_tv box_get channel_turn tv</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6002</td>\n      <td>1_modem_new modem_internet connection_router</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>3769</td>\n      <td>2_bill pay_pay bill_get bill_bill month</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>2979</td>\n      <td>3_cancel service_cancel internet service_servi...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4</td>\n      <td>2163</td>\n      <td>4_street_line_bill_customer</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5</td>\n      <td>2091</td>\n      <td>5_move address_move new address_call move_move...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6</td>\n      <td>1658</td>\n      <td>6_password rogers_password say_password get_pa...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7</td>\n      <td>1443</td>\n      <td>7_call maam_maam call_maam_maam maam</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8</td>\n      <td>1102</td>\n      <td>8_call behalf mother_fathers account_mothers a...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9</td>\n      <td>1028</td>\n      <td>9_appointment cancel_cancel appointment_schedu...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10</td>\n      <td>1008</td>\n      <td>10_rogers email_email get_emails_mailbox</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>11</td>\n      <td>864</td>\n      <td>11_get ignite_ignite tv_rogers ignite_say ignite</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>12</td>\n      <td>739</td>\n      <td>12_cancel home monitor_smart home monitor_home...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>13</td>\n      <td>615</td>\n      <td>13_postal code_code postal code_postal code ge...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>14</td>\n      <td>224</td>\n      <td>14_technician call_call technician_technician ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>15</td>\n      <td>166</td>\n      <td>15_call cancel fido_cancel fido internet_fido ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>16</td>\n      <td>156</td>\n      <td>16_internet promotion_promotion internet_promo...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>17</td>\n      <td>100</td>\n      <td>17_disney subscription_get disney_disney get_d...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>18</td>\n      <td>67</td>\n      <td>18_mohammed cancel service_mohammed account_pa...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>19</td>\n      <td>66</td>\n      <td>19_call get disconnect_call disconnect_get dis...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>20</td>\n      <td>64</td>\n      <td>20_call month_phone month_end month_month call</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>21</td>\n      <td>50</td>\n      <td>21_suspend month_suspend bill_suspend service_...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>22</td>\n      <td>46</td>\n      <td>22_fiber service_fiber internet_phone internet...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>23</td>\n      <td>40</td>\n      <td>23_ipad get_get ipad_ipad go_ipad</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>24</td>\n      <td>38</td>\n      <td>24_get speak french_speak french_speak french ...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>25</td>\n      <td>26</td>\n      <td>25_printer internet_work printer_printer get_p...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>26</td>\n      <td>22</td>\n      <td>26_phone line fax_fax call_phone fax_fax line ...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>27</td>\n      <td>18</td>\n      <td>27_call oclock_get oclock_know oclock open_ocl...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>28</td>\n      <td>15</td>\n      <td>28_address service_mustve cancel email_kevin s...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq = guided_topic_model_processed.get_topic_info()\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0343a88-71e9-4322-ad32-79e33123f5af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## As shown in the following block, topics are fine clustered:       \n",
    "### Such as topic 0 for TV addon, topic 1 for equipment and modem inquiry, topic 2 for billing inquiry, topic 5 and 13 for move and topic 3, 9, 12, 15 for cancel, topic 11 for iginte TV, topic 14 for technician inquiry,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8340e77-bdeb-4b38-b14e-85c6517b4af1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topic</th>\n      <th>Count</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>104269</td>\n      <td>-1_cell phone_home phone_customer_service</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>7255</td>\n      <td>0_remote control_tv box_get channel_turn tv</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6002</td>\n      <td>1_modem_new modem_internet connection_router</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>3769</td>\n      <td>2_bill pay_pay bill_get bill_bill month</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>2979</td>\n      <td>3_cancel service_cancel internet service_servi...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4</td>\n      <td>2163</td>\n      <td>4_street_line_bill_customer</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5</td>\n      <td>2091</td>\n      <td>5_move address_move new address_call move_move...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6</td>\n      <td>1658</td>\n      <td>6_password rogers_password say_password get_pa...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7</td>\n      <td>1443</td>\n      <td>7_call maam_maam call_maam_maam maam</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8</td>\n      <td>1102</td>\n      <td>8_call behalf mother_fathers account_mothers a...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9</td>\n      <td>1028</td>\n      <td>9_appointment cancel_cancel appointment_schedu...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10</td>\n      <td>1008</td>\n      <td>10_rogers email_email get_emails_mailbox</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>11</td>\n      <td>864</td>\n      <td>11_get ignite_ignite tv_rogers ignite_say ignite</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>12</td>\n      <td>739</td>\n      <td>12_cancel home monitor_smart home monitor_home...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>13</td>\n      <td>615</td>\n      <td>13_postal code_code postal code_postal code ge...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>14</td>\n      <td>224</td>\n      <td>14_technician call_call technician_technician ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>15</td>\n      <td>166</td>\n      <td>15_call cancel fido_cancel fido internet_fido ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>16</td>\n      <td>156</td>\n      <td>16_internet promotion_promotion internet_promo...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>17</td>\n      <td>100</td>\n      <td>17_disney subscription_get disney_disney get_d...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>18</td>\n      <td>67</td>\n      <td>18_mohammed cancel service_mohammed account_pa...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topic</th>\n      <th>Count</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>104269</td>\n      <td>-1_cell phone_home phone_customer_service</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>7255</td>\n      <td>0_remote control_tv box_get channel_turn tv</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6002</td>\n      <td>1_modem_new modem_internet connection_router</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>3769</td>\n      <td>2_bill pay_pay bill_get bill_bill month</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>2979</td>\n      <td>3_cancel service_cancel internet service_servi...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4</td>\n      <td>2163</td>\n      <td>4_street_line_bill_customer</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5</td>\n      <td>2091</td>\n      <td>5_move address_move new address_call move_move...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6</td>\n      <td>1658</td>\n      <td>6_password rogers_password say_password get_pa...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7</td>\n      <td>1443</td>\n      <td>7_call maam_maam call_maam_maam maam</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8</td>\n      <td>1102</td>\n      <td>8_call behalf mother_fathers account_mothers a...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9</td>\n      <td>1028</td>\n      <td>9_appointment cancel_cancel appointment_schedu...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10</td>\n      <td>1008</td>\n      <td>10_rogers email_email get_emails_mailbox</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>11</td>\n      <td>864</td>\n      <td>11_get ignite_ignite tv_rogers ignite_say ignite</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>12</td>\n      <td>739</td>\n      <td>12_cancel home monitor_smart home monitor_home...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>13</td>\n      <td>615</td>\n      <td>13_postal code_code postal code_postal code ge...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>14</td>\n      <td>224</td>\n      <td>14_technician call_call technician_technician ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>15</td>\n      <td>166</td>\n      <td>15_call cancel fido_cancel fido internet_fido ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>16</td>\n      <td>156</td>\n      <td>16_internet promotion_promotion internet_promo...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>17</td>\n      <td>100</td>\n      <td>17_disney subscription_get disney_disney get_d...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>18</td>\n      <td>67</td>\n      <td>18_mohammed cancel service_mohammed account_pa...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6757ed4-c2bd-4917-a0d9-ba2680e1e004",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[32]: [('move address', 0.82902545),\n ('move new address', 0.814141),\n ('call move', 0.7979211),\n ('move service', 0.79291254),\n ('address move', 0.7853836),\n ('move move', 0.77695674),\n ('move change', 0.7602319),\n ('move', 0.75284326),\n ('service move', 0.75245863),\n ('move new', 0.74628544)]"
     ]
    }
   ],
   "source": [
    "guided_topic_model_processed.get_topic(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "389554ab-c6cc-4313-a5b5-05f9cdee70c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[33]: [('cancel service', 0.9475236),\n ('cancel internet service', 0.9303482),\n ('service cancel', 0.9178182),\n ('internet cancel', 0.90097195),\n ('cancel internet', 0.8775258),\n ('get cancel', 0.78922474),\n ('canceling', 0.7803995),\n ('cancel', 0.77065384),\n ('cancel cancel', 0.7691685),\n ('call cancel', 0.76684797)]"
     ]
    }
   ],
   "source": [
    "guided_topic_model_processed.get_topic(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2b0580e-e31f-41db-8352-2b566c51dde2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[34]: [('appointment cancel', 0.7422272),\n ('cancel appointment', 0.73458594),\n ('schedule appointment', 0.700595),\n ('reschedule appointment', 0.67970234),\n ('appointment schedule', 0.67012626),\n ('schedule technician', 0.60416454),\n ('cancel internet', 0.5515235),\n ('appointment', 0.54247195),\n ('appointment get', 0.5397885),\n ('cancel service', 0.5311317)]"
     ]
    }
   ],
   "source": [
    "guided_topic_model_processed.get_topic(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c1645b6-a4fa-46a7-a010-6d2ee120dafb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[35]: [('cancel home monitor', 0.8969857),\n ('smart home monitor', 0.69981027),\n ('home monitor', 0.610461),\n ('home monitor system', 0.5986349),\n ('smart home', 0.54229116),\n ('monitor system', 0.4799768),\n ('monitor', 0.47123423),\n ('cancel', 0.43586034),\n ('screen', 0.3232578),\n ('smart', 0.26737633)]"
     ]
    }
   ],
   "source": [
    "guided_topic_model_processed.get_topic(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "259fd1e8-ceca-4e2a-bdc3-f28bdc8f960f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[36]: [('postal code', 0.9705958),\n ('code postal code', 0.95317274),\n ('postal code get', 0.9524472),\n ('postal code postal', 0.9513249),\n ('code postal', 0.93877685),\n ('service postal code', 0.9077622),\n ('postal code know', 0.9038202),\n ('postal code go', 0.89465874),\n ('postal code move', 0.8835842),\n ('internet postal code', 0.8776128)]"
     ]
    }
   ],
   "source": [
    "guided_topic_model_processed.get_topic(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89f54914-4dbe-4dce-9932-77557895c450",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[37]: [('call cancel fido', 0.8503492),\n ('cancel fido internet', 0.81184363),\n ('fido cancel', 0.7642471),\n ('cancel fido', 0.76025105),\n ('call fido', 0.6783703),\n ('fido phone number', 0.6667167),\n ('internet cancel', 0.6639839),\n ('call cancel', 0.6633958),\n ('fido phone', 0.6352875),\n ('internet service fido', 0.6327174)]"
     ]
    }
   ],
   "source": [
    "guided_topic_model_processed.get_topic(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "361607b6-55f7-4e23-bc82-8c6556c04504",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### After the model was trained, use it to transfrom the test dataset and evaluate the metrics on cancel and move categorys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44b127f2-7694-4483-901b-b06ca441664e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e697692d354f3793b05815c86b6c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Batches:   0%|          | 0/11304 [00:00<?, ?it/s]"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "61e697692d354f3793b05815c86b6c5e",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Batches:   0%|          | 0/11304 [00:00<?, ?it/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "d4426be0-9175b1c73a5e5666e0f9edec"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 22:32:09,538 - BERTopic - Reduced dimensionality\n2023-03-15 22:40:27,469 - BERTopic - Calculated probabilities with HDBSCAN\n2023-03-15 22:40:27,470 - BERTopic - Predicted clusters\n"
     ]
    }
   ],
   "source": [
    "inference_guided_topics_processed, inference_guided_probs_processed = guided_topic_model_processed.transform(comparsion_df_pd[\"CLEAN_TEXT_CUSTOMER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08a26faf-32ad-4d90-b53f-4d7ac8b6caf1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[70]: array([0.21190969, 0.0414405 , 0.11500228, 0.0697221 , 0.1311359 ,\n       0.00980058, 0.02268176, 0.00196047, 0.01042774, 0.04141208,\n       0.01857227, 0.00333116, 0.01104373, 0.00197972, 0.00440377,\n       0.00970661, 0.02157798, 0.01606316, 0.00204341, 0.00619947,\n       0.00591042, 0.01272498, 0.00268563, 0.00181886, 0.00823875,\n       0.00179017, 0.00226856, 0.00383816, 0.0029784 ])"
     ]
    }
   ],
   "source": [
    "inference_guided_probs_processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dd93ca7-09bf-484c-bd08-6fe5f8a9c6c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.9.0.min.js\"></script>                <div id=\"0945bb44-68c1-4883-8a64-55e88ee5fdd7\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0945bb44-68c1-4883-8a64-55e88ee5fdd7\")) {                    Plotly.newPlot(                        \"0945bb44-68c1-4883-8a64-55e88ee5fdd7\",                        [{\"marker\":{\"color\":\"#C8D2D7\",\"line\":{\"color\":\"#6E8484\",\"width\":1}},\"orientation\":\"h\",\"x\":[0.03508320862437856,0.11495077711745583,0.08435132161423808,0.1586867252018023,0.08608329859934585,0.03546650692500222,0.03004209891274956,0.02023777359602278,0.05813683401319824,0.015464202691982272],\"y\":[\"<b>Topic 0</b>: remote control_tv box_ge...\",\"<b>Topic 1</b>: modem_new modem_internet...\",\"<b>Topic 2</b>: bill pay_pay bill_get bi...\",\"<b>Topic 3</b>: cancel service_cancel in...\",\"<b>Topic 4</b>: street_line_bill_custome...\",\"<b>Topic 5</b>: move address_move new ad...\",\"<b>Topic 10</b>: rogers email_email get_...\",\"<b>Topic 11</b>: get ignite_ignite tv_ro...\",\"<b>Topic 13</b>: postal code_code postal...\",\"<b>Topic 20</b>: call month_phone month_...\"],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"<b>Topic Probability Distribution</b>\",\"y\":0.95,\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"xaxis\":{\"title\":{\"text\":\"Probability\"}},\"width\":800,\"height\":600},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.9.0.min.js\"></script>                <div id=\"0945bb44-68c1-4883-8a64-55e88ee5fdd7\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0945bb44-68c1-4883-8a64-55e88ee5fdd7\")) {                    Plotly.newPlot(                        \"0945bb44-68c1-4883-8a64-55e88ee5fdd7\",                        [{\"marker\":{\"color\":\"#C8D2D7\",\"line\":{\"color\":\"#6E8484\",\"width\":1}},\"orientation\":\"h\",\"x\":[0.03508320862437856,0.11495077711745583,0.08435132161423808,0.1586867252018023,0.08608329859934585,0.03546650692500222,0.03004209891274956,0.02023777359602278,0.05813683401319824,0.015464202691982272],\"y\":[\"<b>Topic 0</b>: remote control_tv box_ge...\",\"<b>Topic 1</b>: modem_new modem_internet...\",\"<b>Topic 2</b>: bill pay_pay bill_get bi...\",\"<b>Topic 3</b>: cancel service_cancel in...\",\"<b>Topic 4</b>: street_line_bill_custome...\",\"<b>Topic 5</b>: move address_move new ad...\",\"<b>Topic 10</b>: rogers email_email get_...\",\"<b>Topic 11</b>: get ignite_ignite tv_ro...\",\"<b>Topic 13</b>: postal code_code postal...\",\"<b>Topic 20</b>: call month_phone month_...\"],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"<b>Topic Probability Distribution</b>\",\"y\":0.95,\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"xaxis\":{\"title\":{\"text\":\"Probability\"}},\"width\":800,\"height\":600},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "guided_topic_model_processed.visualize_distribution(inference_guided_probs_processed[0], min_probability=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e032c8a1-9ba1-4002-89f5-ab65b49d1724",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#subset=comparsion_df_pd[\"CLEAN_TEXT_CUSTOMER\"]\n",
    "inference_guided_topics_processed, inference_guided_probs_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "163f6599-7fd3-4d9b-8448-d8b7ebcb07f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[41]: array([[3.50832086e-02, 1.14950777e-01, 8.43513216e-02, ...,\n        6.41267627e-03, 9.40349561e-04, 1.00084706e-03],\n       [9.73018869e-40, 1.78827518e-39, 9.16852249e-40, ...,\n        1.30339012e-40, 1.05139739e-40, 1.26813533e-40],\n       [4.02585683e-24, 1.79675506e-23, 4.53224908e-24, ...,\n        1.07321202e-24, 5.83158995e-28, 1.40065202e-28],\n       ...,\n       [2.47531418e-01, 2.07300433e-02, 1.50011490e-02, ...,\n        3.23742598e-04, 2.90870733e-04, 3.21338222e-04],\n       [1.82756725e-02, 2.49313500e-02, 1.37514497e-02, ...,\n        1.28894147e-03, 1.15547632e-03, 1.27073263e-03],\n       [2.68042123e-02, 8.52529825e-01, 1.15970913e-02, ...,\n        5.22197095e-07, 1.42191062e-07, 1.00113239e-07]])"
     ]
    }
   ],
   "source": [
    "inference_guided_probs_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d22ce02-be1d-4e35-8438-d8d2ba3fcfa8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Save the topic probability for future usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5b821fd-5369-4bb4-b7d8-773dd54e5ee1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['topic_0', 'topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5', 'topic_6', 'topic_7', 'topic_8', 'topic_9', 'topic_10', 'topic_11', 'topic_12', 'topic_13', 'topic_14', 'topic_15', 'topic_16', 'topic_17', 'topic_18', 'topic_19', 'topic_20', 'topic_21', 'topic_22', 'topic_23', 'topic_24', 'topic_25', 'topic_26', 'topic_27', 'topic_28']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lis1=[]\n",
    "for i in range(29):\n",
    "    lis1.append(\"topic_\"+str(i))\n",
    "print(lis1)\n",
    "saved_probs=pd.DataFrame(data=inference_guided_probs_processed,columns=lis1)\n",
    "saved_probs_spark=spark.createDataFrame(saved_probs)\n",
    "saved_probs_spark_path=\"dbfs:/mnt/ml-model-output-scores-data/mlmodel_output/digital/CD4MT/Verint/GLDA_Topic_Modelling_Output/Connected_Home/df_bert_spark_saved_probs\"\n",
    "saved_probs_spark.write.mode(\"overwrite\").option(\"header\", True).parquet(saved_probs_spark_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0361eef-ba83-4d3f-b20b-e890455184fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SPEECH_ID_VERINT</th>\n      <th>CLEAN_TEXT_CUSTOMER</th>\n      <th>cancel</th>\n      <th>move</th>\n      <th>cancel_mention</th>\n      <th>move_mention</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>504060085267811</td>\n      <td>know account suspend go come account suspend k...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>504042085789731</td>\n      <td>know tactic know say signal recheck avenue say...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>504052084807090</td>\n      <td>personal blockage david problem know go know m...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>504062085789419</td>\n      <td>internet hall phone rogers associate associate...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>504068084886774</td>\n      <td>picket rogers internet order mart internet iss...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>361709</th>\n      <td>504050086869885</td>\n      <td>rogers guess use go able modem innovation mont...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>361710</th>\n      <td>504032085471372</td>\n      <td>love book speak tell hear month mary postal co...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>361711</th>\n      <td>504036086648471</td>\n      <td>account use charge problem account reason mont...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>361712</th>\n      <td>504042085504653</td>\n      <td>market watch nancy go remember answer question...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>361713</th>\n      <td>504026085365651</td>\n      <td>wifi high high spring carrier heart disconnect...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>361714 rows × 6 columns</p>\n</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SPEECH_ID_VERINT</th>\n      <th>CLEAN_TEXT_CUSTOMER</th>\n      <th>cancel</th>\n      <th>move</th>\n      <th>cancel_mention</th>\n      <th>move_mention</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>504060085267811</td>\n      <td>know account suspend go come account suspend k...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>504042085789731</td>\n      <td>know tactic know say signal recheck avenue say...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>504052084807090</td>\n      <td>personal blockage david problem know go know m...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>504062085789419</td>\n      <td>internet hall phone rogers associate associate...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>504068084886774</td>\n      <td>picket rogers internet order mart internet iss...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>361709</th>\n      <td>504050086869885</td>\n      <td>rogers guess use go able modem innovation mont...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>361710</th>\n      <td>504032085471372</td>\n      <td>love book speak tell hear month mary postal co...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>361711</th>\n      <td>504036086648471</td>\n      <td>account use charge problem account reason mont...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>361712</th>\n      <td>504042085504653</td>\n      <td>market watch nancy go remember answer question...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>361713</th>\n      <td>504026085365651</td>\n      <td>wifi high high spring carrier heart disconnect...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>361714 rows × 6 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparsion_df_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "529d9178-9305-4de8-a1a9-321e2bdaacef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create cancel and move evaluation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1744c934-4bc1-4ea8-95eb-eb232d72080e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SPEECH_ID_VERINT</th>\n      <th>CLEAN_TEXT_CUSTOMER</th>\n      <th>cancel</th>\n      <th>cancel_mention</th>\n      <th>move</th>\n      <th>move_mention</th>\n      <th>cancel_main_bert_prob</th>\n      <th>cancel_appoint_bert_prob</th>\n      <th>cancel_monitor_bert_prob</th>\n      <th>cancel_fido_bert_prob</th>\n      <th>move_main_bert_prob</th>\n      <th>move_postal_bert_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>504060085267811</td>\n      <td>know account suspend go come account suspend k...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.586867e-01</td>\n      <td>1.214076e-02</td>\n      <td>8.009574e-03</td>\n      <td>5.917426e-03</td>\n      <td>3.546651e-02</td>\n      <td>5.813683e-02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>504042085789731</td>\n      <td>know tactic know say signal recheck avenue say...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.225734e-39</td>\n      <td>2.632841e-40</td>\n      <td>3.641440e-40</td>\n      <td>1.733897e-40</td>\n      <td>4.122045e-40</td>\n      <td>5.397220e-40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>504052084807090</td>\n      <td>personal blockage david problem know go know m...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>9.948376e-24</td>\n      <td>1.486336e-16</td>\n      <td>8.956138e-01</td>\n      <td>1.221124e-19</td>\n      <td>3.086363e-24</td>\n      <td>4.250572e-24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>504062085789419</td>\n      <td>internet hall phone rogers associate associate...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>7.051140e-05</td>\n      <td>4.278857e-06</td>\n      <td>1.962694e-10</td>\n      <td>8.426420e-11</td>\n      <td>4.579164e-08</td>\n      <td>1.518287e-05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>504068084886774</td>\n      <td>picket rogers internet order mart internet iss...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>4.812843e-13</td>\n      <td>2.417653e-09</td>\n      <td>1.101782e-13</td>\n      <td>6.856982e-14</td>\n      <td>1.218361e-13</td>\n      <td>2.012626e-13</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>361709</th>\n      <td>504050086869885</td>\n      <td>rogers guess use go able modem innovation mont...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>3.372735e-02</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>361710</th>\n      <td>504032085471372</td>\n      <td>love book speak tell hear month mary postal co...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.964775e-58</td>\n      <td>3.018073e-59</td>\n      <td>2.559357e-59</td>\n      <td>1.867847e-01</td>\n      <td>6.296916e-59</td>\n      <td>8.753205e-59</td>\n    </tr>\n    <tr>\n      <th>361711</th>\n      <td>504036086648471</td>\n      <td>account use charge problem account reason mont...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>3.911282e-03</td>\n      <td>7.655489e-04</td>\n      <td>6.740866e-03</td>\n      <td>5.352024e-04</td>\n      <td>1.156537e-03</td>\n      <td>1.646747e-03</td>\n    </tr>\n    <tr>\n      <th>361712</th>\n      <td>504042085504653</td>\n      <td>market watch nancy go remember answer question...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.540757e-02</td>\n      <td>3.148782e-03</td>\n      <td>5.986110e-03</td>\n      <td>2.122089e-03</td>\n      <td>4.651569e-03</td>\n      <td>6.569071e-03</td>\n    </tr>\n    <tr>\n      <th>361713</th>\n      <td>504026085365651</td>\n      <td>wifi high high spring carrier heart disconnect...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>3.965511e-05</td>\n      <td>2.849036e-06</td>\n      <td>7.287840e-07</td>\n      <td>4.066356e-07</td>\n      <td>4.011617e-06</td>\n      <td>1.039722e-05</td>\n    </tr>\n  </tbody>\n</table>\n<p>361714 rows × 12 columns</p>\n</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SPEECH_ID_VERINT</th>\n      <th>CLEAN_TEXT_CUSTOMER</th>\n      <th>cancel</th>\n      <th>cancel_mention</th>\n      <th>move</th>\n      <th>move_mention</th>\n      <th>cancel_main_bert_prob</th>\n      <th>cancel_appoint_bert_prob</th>\n      <th>cancel_monitor_bert_prob</th>\n      <th>cancel_fido_bert_prob</th>\n      <th>move_main_bert_prob</th>\n      <th>move_postal_bert_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>504060085267811</td>\n      <td>know account suspend go come account suspend k...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.586867e-01</td>\n      <td>1.214076e-02</td>\n      <td>8.009574e-03</td>\n      <td>5.917426e-03</td>\n      <td>3.546651e-02</td>\n      <td>5.813683e-02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>504042085789731</td>\n      <td>know tactic know say signal recheck avenue say...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.225734e-39</td>\n      <td>2.632841e-40</td>\n      <td>3.641440e-40</td>\n      <td>1.733897e-40</td>\n      <td>4.122045e-40</td>\n      <td>5.397220e-40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>504052084807090</td>\n      <td>personal blockage david problem know go know m...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>9.948376e-24</td>\n      <td>1.486336e-16</td>\n      <td>8.956138e-01</td>\n      <td>1.221124e-19</td>\n      <td>3.086363e-24</td>\n      <td>4.250572e-24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>504062085789419</td>\n      <td>internet hall phone rogers associate associate...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>7.051140e-05</td>\n      <td>4.278857e-06</td>\n      <td>1.962694e-10</td>\n      <td>8.426420e-11</td>\n      <td>4.579164e-08</td>\n      <td>1.518287e-05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>504068084886774</td>\n      <td>picket rogers internet order mart internet iss...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>4.812843e-13</td>\n      <td>2.417653e-09</td>\n      <td>1.101782e-13</td>\n      <td>6.856982e-14</td>\n      <td>1.218361e-13</td>\n      <td>2.012626e-13</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>361709</th>\n      <td>504050086869885</td>\n      <td>rogers guess use go able modem innovation mont...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>3.372735e-02</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>361710</th>\n      <td>504032085471372</td>\n      <td>love book speak tell hear month mary postal co...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.964775e-58</td>\n      <td>3.018073e-59</td>\n      <td>2.559357e-59</td>\n      <td>1.867847e-01</td>\n      <td>6.296916e-59</td>\n      <td>8.753205e-59</td>\n    </tr>\n    <tr>\n      <th>361711</th>\n      <td>504036086648471</td>\n      <td>account use charge problem account reason mont...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>3.911282e-03</td>\n      <td>7.655489e-04</td>\n      <td>6.740866e-03</td>\n      <td>5.352024e-04</td>\n      <td>1.156537e-03</td>\n      <td>1.646747e-03</td>\n    </tr>\n    <tr>\n      <th>361712</th>\n      <td>504042085504653</td>\n      <td>market watch nancy go remember answer question...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.540757e-02</td>\n      <td>3.148782e-03</td>\n      <td>5.986110e-03</td>\n      <td>2.122089e-03</td>\n      <td>4.651569e-03</td>\n      <td>6.569071e-03</td>\n    </tr>\n    <tr>\n      <th>361713</th>\n      <td>504026085365651</td>\n      <td>wifi high high spring carrier heart disconnect...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>3.965511e-05</td>\n      <td>2.849036e-06</td>\n      <td>7.287840e-07</td>\n      <td>4.066356e-07</td>\n      <td>4.011617e-06</td>\n      <td>1.039722e-05</td>\n    </tr>\n  </tbody>\n</table>\n<p>361714 rows × 12 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_bert = pd.DataFrame({\"SPEECH_ID_VERINT\": comparsion_df_pd[\"SPEECH_ID_VERINT\"], \n",
    "                   \"CLEAN_TEXT_CUSTOMER\": comparsion_df_pd[\"CLEAN_TEXT_CUSTOMER\"], \n",
    "                   \"cancel\": comparsion_df_pd[\"cancel\"], #label\n",
    "                   \"move\": comparsion_df_pd[\"move\"], #label\n",
    "                   \"cancel_main_bert_prob\": [row[3] for row in inference_guided_probs_processed],\n",
    "                   \"cancel_appoint_bert_prob\": [row[9] for row in inference_guided_probs_processed],\n",
    "                   \"cancel_monitor_bert_prob\": [row[12] for row in inference_guided_probs_processed],\n",
    "                   \"cancel_fido_bert_prob\": [row[15] for row in inference_guided_probs_processed],\n",
    "                   \"move_main_bert_prob\": [row[5] for row in inference_guided_probs_processed],\n",
    "                   \"move_postal_bert_prob\": [row[13] for row in inference_guided_probs_processed]\n",
    "                       })\n",
    "\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "df_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89210cc5-e4a0-4a9d-97ad-fd1cb07a57c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_bert[\"label_cancel\"]= np.where((df_bert[\"cancel\"]==True)), True, False)\n",
    "df_bert[\"label_move\"]= np.where((df_bert[\"move\"]==True)), True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "269195fd-fd1a-4f03-8bd7-73742bb331d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bert_spark=spark.createDataFrame(df_bert)\n",
    "df_bert_spark_path=\"dbfs:/mnt/ml-model-output-scores-data/mlmodel_output/digital/CD4MT/Verint/GLDA_Topic_Modelling_Output/Connected_Home/df_bert_spark_inference\"\n",
    "df_bert_spark.write.mode(\"overwrite\").option(\"header\", True).parquet(df_bert_spark_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "031fe788-2a61-4ccd-9d10-b4610e2d39cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bert_spark_path=\"dbfs:/mnt/ml-model-output-scores-data/mlmodel_output/digital/CD4MT/Verint/GLDA_Topic_Modelling_Output/Connected_Home/df_bert_spark_inference\"\n",
    "df_bert_spark=spark.read.parquet(df_bert_spark_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08292d93-71ab-4f34-8179-24b6b963ee21",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Evaluation on bertopic for label cancel and label move:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccd7c552-0519-477f-b436-c5382b8aba84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 4908\nTN count: 282293\nFP count: 12078\nFN count: 62435\nPrecision: 0.28894383610031793\nRecall: 0.07288062604873558\nAccuracy: 0.7940002322276716\n"
     ]
    }
   ],
   "source": [
    "#calculate metrics or bert\n",
    "#threshold for cancel at 0.40\n",
    "tp_cancel = df_bert_spark.filter(col(\"label_cancel\") == True).filter((col(\"cancel_main_bert_prob\") >= 0.40) | (col(\"cancel_appoint_bert_prob\") >= 0.40) | (col(\"cancel_monitor_bert_prob\") >= 0.40) | (col(\"cancel_fido_bert_prob\") >= 0.40)).count()\n",
    "print(f\"TP count: {tp_cancel}\")\n",
    "\n",
    "tn_cancel = df_bert_spark.filter(col(\"label_cancel\") == False).filter((col(\"cancel_main_bert_prob\") < 0.40) & (col(\"cancel_appoint_bert_prob\") < 0.40) & (col(\"cancel_monitor_bert_prob\") < 0.40) & (col(\"cancel_fido_bert_prob\") < 0.40)).count()\n",
    "print(f\"TN count: {tn_cancel}\")\n",
    "\n",
    "fp_cancel = df_bert_spark.filter(col(\"label_cancel\") == False).filter((col(\"cancel_main_bert_prob\") >= 0.40) | (col(\"cancel_appoint_bert_prob\") >= 0.40) | (col(\"cancel_monitor_bert_prob\") >= 0.40) | (col(\"cancel_fido_bert_prob\") >= 0.40)).count()\n",
    "print(f\"FP count: {fp_cancel}\")\n",
    "\n",
    "fn_cancel = df_bert_spark.filter(col(\"label_cancel\") == True).filter((col(\"cancel_main_bert_prob\") < 0.40) & (col(\"cancel_appoint_bert_prob\") < 0.40) & (col(\"cancel_monitor_bert_prob\") < 0.40) & (col(\"cancel_fido_bert_prob\") < 0.40)).count()\n",
    "print(f\"FN count: {fn_cancel}\")\n",
    "\n",
    "precision_cancel = tp_cancel / (tp_cancel + fp_cancel)\n",
    "print(f\"Precision: {precision_cancel}\")\n",
    "\n",
    "recall_cancel = tp_cancel / (tp_cancel + fn_cancel)\n",
    "print(f\"Recall: {recall_cancel}\")\n",
    "Accuracy = (tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel) \n",
    "print(f\"Accuracy: {(tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel)}\")\n",
    "\n",
    "cancel = [('cancel', tp_cancel, tn_cancel, fp_cancel, fn_cancel, precision_cancel, recall_cancel, Accuracy)]\n",
    "f7 = spark.createDataFrame(data=cancel, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8505f43e-ded1-4846-ad4e-c510bb7b4c4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 13325\nTN count: 249411\nFP count: 44960\nFN count: 54018\nPrecision: 0.2286179977695805\nRecall: 0.19786763286458875\nAccuracy: 0.7263639228782961\n"
     ]
    }
   ],
   "source": [
    "#calculate metrics or bert\n",
    "#threshold for cancel at 0.10\n",
    "tp_cancel = df_bert_spark.filter(col(\"label_cancel\") == True).filter((col(\"cancel_main_bert_prob\") >= 0.10) | (col(\"cancel_appoint_bert_prob\") >= 0.10) | (col(\"cancel_monitor_bert_prob\") >= 0.10) | (col(\"cancel_fido_bert_prob\") >= 0.10)).count()\n",
    "print(f\"TP count: {tp_cancel}\")\n",
    "\n",
    "tn_cancel = df_bert_spark.filter(col(\"label_cancel\") == False).filter((col(\"cancel_main_bert_prob\") < 0.10) & (col(\"cancel_appoint_bert_prob\") < 0.10) & (col(\"cancel_monitor_bert_prob\") < 0.10) & (col(\"cancel_fido_bert_prob\") < 0.10)).count()\n",
    "print(f\"TN count: {tn_cancel}\")\n",
    "\n",
    "fp_cancel = df_bert_spark.filter(col(\"label_cancel\") == False).filter((col(\"cancel_main_bert_prob\") >= 0.10) | (col(\"cancel_appoint_bert_prob\") >= 0.10) | (col(\"cancel_monitor_bert_prob\") >= 0.10) | (col(\"cancel_fido_bert_prob\") >= 0.10)).count()\n",
    "print(f\"FP count: {fp_cancel}\")\n",
    "\n",
    "fn_cancel = df_bert_spark.filter(col(\"label_cancel\") == True).filter((col(\"cancel_main_bert_prob\") < 0.10) & (col(\"cancel_appoint_bert_prob\") < 0.10) & (col(\"cancel_monitor_bert_prob\") < 0.10) & (col(\"cancel_fido_bert_prob\") < 0.10)).count()\n",
    "print(f\"FN count: {fn_cancel}\")\n",
    "\n",
    "precision_cancel = tp_cancel / (tp_cancel + fp_cancel)\n",
    "print(f\"Precision: {precision_cancel}\")\n",
    "\n",
    "recall_cancel = tp_cancel / (tp_cancel + fn_cancel)\n",
    "print(f\"Recall: {recall_cancel}\")\n",
    "Accuracy = (tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel) \n",
    "print(f\"Accuracy: {(tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel)}\")\n",
    "\n",
    "cancel = [('cancel', tp_cancel, tn_cancel, fp_cancel, fn_cancel, precision_cancel, recall_cancel, Accuracy)]\n",
    "f7 = spark.createDataFrame(data=cancel, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46ff925c-4d4a-473e-adc3-a4bd0a4491ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 16687\nTN count: 223901\nFP count: 70470\nFN count: 50656\nPrecision: 0.19145909106554837\nRecall: 0.24779115869503884\nAccuracy: 0.6651332268034967\n"
     ]
    }
   ],
   "source": [
    "#calculate metrics or bert\n",
    "#threshold for cancel at 0.05\n",
    "tp_cancel = df_bert_spark.filter(col(\"label_cancel\") == True).filter((col(\"cancel_main_bert_prob\") >= 0.05) | (col(\"cancel_appoint_bert_prob\") >= 0.05) | (col(\"cancel_monitor_bert_prob\") >= 0.05) | (col(\"cancel_fido_bert_prob\") >= 0.05)).count()\n",
    "print(f\"TP count: {tp_cancel}\")\n",
    "\n",
    "tn_cancel = df_bert_spark.filter(col(\"label_cancel\") == False).filter((col(\"cancel_main_bert_prob\") < 0.05) & (col(\"cancel_appoint_bert_prob\") < 0.05) & (col(\"cancel_monitor_bert_prob\") < 0.05) & (col(\"cancel_fido_bert_prob\") < 0.05)).count()\n",
    "print(f\"TN count: {tn_cancel}\")\n",
    "\n",
    "fp_cancel = df_bert_spark.filter(col(\"label_cancel\") == False).filter((col(\"cancel_main_bert_prob\") >= 0.05) | (col(\"cancel_appoint_bert_prob\") >= 0.05) | (col(\"cancel_monitor_bert_prob\") >= 0.05) | (col(\"cancel_fido_bert_prob\") >= 0.05)).count()\n",
    "print(f\"FP count: {fp_cancel}\")\n",
    "\n",
    "fn_cancel = df_bert_spark.filter(col(\"label_cancel\") == True).filter((col(\"cancel_main_bert_prob\") < 0.05) & (col(\"cancel_appoint_bert_prob\") < 0.05) & (col(\"cancel_monitor_bert_prob\") < 0.05) & (col(\"cancel_fido_bert_prob\") < 0.05)).count()\n",
    "print(f\"FN count: {fn_cancel}\")\n",
    "\n",
    "precision_cancel = tp_cancel / (tp_cancel + fp_cancel)\n",
    "print(f\"Precision: {precision_cancel}\")\n",
    "\n",
    "recall_cancel = tp_cancel / (tp_cancel + fn_cancel)\n",
    "print(f\"Recall: {recall_cancel}\")\n",
    "Accuracy = (tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel) \n",
    "print(f\"Accuracy: {(tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel)}\")\n",
    "\n",
    "cancel = [('cancel', tp_cancel, tn_cancel, fp_cancel, fn_cancel, precision_cancel, recall_cancel, Accuracy)]\n",
    "f7 = spark.createDataFrame(data=cancel, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "481a22d2-7de4-4946-9c61-f6931771f87e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 24836\nTN count: 186292\nFP count: 108079\nFN count: 42507\nPrecision: 0.18685626152052062\nRecall: 0.3687985388236342\nAccuracy: 0.5836876648401776\n"
     ]
    }
   ],
   "source": [
    "#calculate metrics or bert\n",
    "#threshold for cancel at 0.01\n",
    "tp_cancel = df_bert_spark.filter(col(\"label_cancel\") == True).filter((col(\"cancel_main_bert_prob\") >= 0.01) | (col(\"cancel_appoint_bert_prob\") >= 0.01) | (col(\"cancel_monitor_bert_prob\") >= 0.01) | (col(\"cancel_fido_bert_prob\") >= 0.01)).count()\n",
    "print(f\"TP count: {tp_cancel}\")\n",
    "\n",
    "tn_cancel = df_bert_spark.filter(col(\"label_cancel\") == False).filter((col(\"cancel_main_bert_prob\") < 0.01) & (col(\"cancel_appoint_bert_prob\") < 0.01) & (col(\"cancel_monitor_bert_prob\") < 0.01) & (col(\"cancel_fido_bert_prob\") < 0.01)).count()\n",
    "print(f\"TN count: {tn_cancel}\")\n",
    "\n",
    "fp_cancel = df_bert_spark.filter(col(\"label_cancel\") == False).filter((col(\"cancel_main_bert_prob\") >= 0.01) | (col(\"cancel_appoint_bert_prob\") >= 0.01) | (col(\"cancel_monitor_bert_prob\") >= 0.01) | (col(\"cancel_fido_bert_prob\") >= 0.01)).count()\n",
    "print(f\"FP count: {fp_cancel}\")\n",
    "\n",
    "fn_cancel = df_bert_spark.filter(col(\"label_cancel\") == True).filter((col(\"cancel_main_bert_prob\") < 0.01) & (col(\"cancel_appoint_bert_prob\") < 0.01) & (col(\"cancel_monitor_bert_prob\") < 0.01) & (col(\"cancel_fido_bert_prob\") < 0.01)).count()\n",
    "print(f\"FN count: {fn_cancel}\")\n",
    "\n",
    "precision_cancel = tp_cancel / (tp_cancel + fp_cancel)\n",
    "print(f\"Precision: {precision_cancel}\")\n",
    "\n",
    "recall_cancel = tp_cancel / (tp_cancel + fn_cancel)\n",
    "print(f\"Recall: {recall_cancel}\")\n",
    "Accuracy = (tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel) \n",
    "print(f\"Accuracy: {(tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel)}\")\n",
    "\n",
    "cancel = [('cancel', tp_cancel, tn_cancel, fp_cancel, fn_cancel, precision_cancel, recall_cancel, Accuracy)]\n",
    "f7 = spark.createDataFrame(data=cancel, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "406a700f-df7d-4997-9e44-d594079127fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 27067\nTN count: 178822\nFP count: 115549\nFN count: 40276\nPrecision: 0.18978936444718686\nRecall: 0.4019274460597241\nAccuracy: 0.5692038461325799\n"
     ]
    }
   ],
   "source": [
    "#calculate metrics or bert\n",
    "#threshold for cancel at 0.005\n",
    "tp_cancel = df_bert_spark.filter(col(\"label_cancel\") == True).filter((col(\"cancel_main_bert_prob\") >= 0.005) | (col(\"cancel_appoint_bert_prob\") >= 0.005) | (col(\"cancel_monitor_bert_prob\") >= 0.005) | (col(\"cancel_fido_bert_prob\") >= 0.005)).count()\n",
    "print(f\"TP count: {tp_cancel}\")\n",
    "\n",
    "tn_cancel = df_bert_spark.filter(col(\"label_cancel\") == False).filter((col(\"cancel_main_bert_prob\") < 0.005) & (col(\"cancel_appoint_bert_prob\") < 0.005) & (col(\"cancel_monitor_bert_prob\") < 0.005) & (col(\"cancel_fido_bert_prob\") < 0.005)).count()\n",
    "print(f\"TN count: {tn_cancel}\")\n",
    "\n",
    "fp_cancel = df_bert_spark.filter(col(\"label_cancel\") == False).filter((col(\"cancel_main_bert_prob\") >= 0.005) | (col(\"cancel_appoint_bert_prob\") >= 0.005) | (col(\"cancel_monitor_bert_prob\") >= 0.005) | (col(\"cancel_fido_bert_prob\") >= 0.005)).count()\n",
    "print(f\"FP count: {fp_cancel}\")\n",
    "\n",
    "fn_cancel = df_bert_spark.filter(col(\"label_cancel\") == True).filter((col(\"cancel_main_bert_prob\") < 0.005) & (col(\"cancel_appoint_bert_prob\") < 0.005) & (col(\"cancel_monitor_bert_prob\") < 0.005) & (col(\"cancel_fido_bert_prob\") < 0.005)).count()\n",
    "print(f\"FN count: {fn_cancel}\")\n",
    "\n",
    "precision_cancel = tp_cancel / (tp_cancel + fp_cancel)\n",
    "print(f\"Precision: {precision_cancel}\")\n",
    "\n",
    "recall_cancel = tp_cancel / (tp_cancel + fn_cancel)\n",
    "print(f\"Recall: {recall_cancel}\")\n",
    "Accuracy = (tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel) \n",
    "print(f\"Accuracy: {(tp_cancel + tn_cancel) / (tp_cancel + fp_cancel + fn_cancel + tn_cancel)}\")\n",
    "\n",
    "cancel = [('cancel', tp_cancel, tn_cancel, fp_cancel, fn_cancel, precision_cancel, recall_cancel, Accuracy)]\n",
    "f7 = spark.createDataFrame(data=cancel, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d0e1b2d-5919-4c89-9b0d-ffcda6ba7ec5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 2173\nTN count: 258875\nFP count: 1864\nFN count: 98802\nPrecision: 0.5382709933118652\nRecall: 0.021520178261946025\nAccuracy: 0.7216972525254759\n"
     ]
    }
   ],
   "source": [
    "#move, threshold 0.20\n",
    "tp_moves = df_bert_spark.filter(col(\"label_move\") == True).filter((col(\"move_main_bert_prob\") >= 0.20) | (col(\"move_postal_bert_prob\") >= 0.20)).count()\n",
    "print(f\"TP count: {tp_moves}\")\n",
    "\n",
    "tn_moves = df_bert_spark.filter(col(\"label_move\") == False).filter((col(\"move_main_bert_prob\") < 0.20) & (col(\"move_postal_bert_prob\") < 0.20)).count()\n",
    "print(f\"TN count: {tn_moves}\")\n",
    "\n",
    "fp_moves = df_bert_spark.filter(col(\"label_move\") == False).filter((col(\"move_main_bert_prob\") >= 0.20) | (col(\"move_postal_bert_prob\") >= 0.20)).count()\n",
    "print(f\"FP count: {fp_moves}\")\n",
    "\n",
    "fn_moves = df_bert_spark.filter(col(\"label_move\") == True).filter((col(\"move_main_bert_prob\") < 0.20) & (col(\"move_postal_bert_prob\") < 0.20)).count()\n",
    "print(f\"FN count: {fn_moves}\")\n",
    "\n",
    "precision_moves = tp_moves / (tp_moves + fp_moves)\n",
    "print(f\"Precision: {precision_moves}\")\n",
    "Accuracy = (tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)\n",
    "recall_moves = tp_moves / (tp_moves + fn_moves)\n",
    "print(f\"Recall: {recall_moves}\")\n",
    "print(f\"Accuracy: {(tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)}\")\n",
    "\n",
    "move = [('moves', tp_moves, tn_moves, fp_moves, fn_moves, precision_moves, recall_moves, Accuracy)]\n",
    "f3 = spark.createDataFrame(data=move, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e302941f-6f15-4b6b-a540-4c4ad66d4557",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 4497\nTN count: 254473\nFP count: 6266\nFN count: 96478\nPrecision: 0.4178203103224008\nRecall: 0.044535776182223326\nAccuracy: 0.7159523822688644\n"
     ]
    }
   ],
   "source": [
    "#move, threshold 0.10\n",
    "tp_moves = df_bert_spark.filter(col(\"label_move\") == True).filter((col(\"move_main_bert_prob\") >= 0.10) | (col(\"move_postal_bert_prob\") >= 0.10)).count()\n",
    "print(f\"TP count: {tp_moves}\")\n",
    "\n",
    "tn_moves = df_bert_spark.filter(col(\"label_move\") == False).filter((col(\"move_main_bert_prob\") < 0.10) & (col(\"move_postal_bert_prob\") < 0.10)).count()\n",
    "print(f\"TN count: {tn_moves}\")\n",
    "\n",
    "fp_moves = df_bert_spark.filter(col(\"label_move\") == False).filter((col(\"move_main_bert_prob\") >= 0.10) | (col(\"move_postal_bert_prob\") >= 0.10)).count()\n",
    "print(f\"FP count: {fp_moves}\")\n",
    "\n",
    "fn_moves = df_bert_spark.filter(col(\"label_move\") == True).filter((col(\"move_main_bert_prob\") < 0.10) & (col(\"move_postal_bert_prob\") < 0.10)).count()\n",
    "print(f\"FN count: {fn_moves}\")\n",
    "\n",
    "precision_moves = tp_moves / (tp_moves + fp_moves)\n",
    "print(f\"Precision: {precision_moves}\")\n",
    "Accuracy = (tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)\n",
    "recall_moves = tp_moves / (tp_moves + fn_moves)\n",
    "print(f\"Recall: {recall_moves}\")\n",
    "print(f\"Accuracy: {(tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)}\")\n",
    "\n",
    "move = [('moves', tp_moves, tn_moves, fp_moves, fn_moves, precision_moves, recall_moves, Accuracy)]\n",
    "f3 = spark.createDataFrame(data=move, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7f009dc-f98a-44b0-bfc3-e478f3bd0e3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 7268\nTN count: 247895\nFP count: 12844\nFN count: 93707\nPrecision: 0.36137629276054095\nRecall: 0.07197821242881901\nAccuracy: 0.7054274924387776\n"
     ]
    }
   ],
   "source": [
    "#move, threshold 0.05\n",
    "tp_moves = df_bert_spark.filter(col(\"label_move\") == True).filter((col(\"move_main_bert_prob\") >= 0.05) | (col(\"move_postal_bert_prob\") >= 0.05)).count()\n",
    "print(f\"TP count: {tp_moves}\")\n",
    "\n",
    "tn_moves = df_bert_spark.filter(col(\"label_move\") == False).filter((col(\"move_main_bert_prob\") < 0.05) & (col(\"move_postal_bert_prob\") < 0.05)).count()\n",
    "print(f\"TN count: {tn_moves}\")\n",
    "\n",
    "fp_moves = df_bert_spark.filter(col(\"label_move\") == False).filter((col(\"move_main_bert_prob\") >= 0.05) | (col(\"move_postal_bert_prob\") >= 0.05)).count()\n",
    "print(f\"FP count: {fp_moves}\")\n",
    "\n",
    "fn_moves = df_bert_spark.filter(col(\"label_move\") == True).filter((col(\"move_main_bert_prob\") < 0.05) & (col(\"move_postal_bert_prob\") < 0.05)).count()\n",
    "print(f\"FN count: {fn_moves}\")\n",
    "\n",
    "precision_moves = tp_moves / (tp_moves + fp_moves)\n",
    "print(f\"Precision: {precision_moves}\")\n",
    "Accuracy = (tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)\n",
    "recall_moves = tp_moves / (tp_moves + fn_moves)\n",
    "print(f\"Recall: {recall_moves}\")\n",
    "print(f\"Accuracy: {(tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)}\")\n",
    "\n",
    "move = [('moves', tp_moves, tn_moves, fp_moves, fn_moves, precision_moves, recall_moves, Accuracy)]\n",
    "f3 = spark.createDataFrame(data=move, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff3da6ca-5d72-42bc-abd8-cdfc0124fb10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 20746\nTN count: 205424\nFP count: 55315\nFN count: 80229\nPrecision: 0.2727547626247354\nRecall: 0.20545679623669225\nAccuracy: 0.6252730057448702\n"
     ]
    }
   ],
   "source": [
    "#move, threshold 0.01\n",
    "tp_moves = df_bert_spark.filter(col(\"label_move\") == True).filter((col(\"move_main_bert_prob\") >= 0.01) | (col(\"move_postal_bert_prob\") >= 0.01)).count()\n",
    "print(f\"TP count: {tp_moves}\")\n",
    "\n",
    "tn_moves = df_bert_spark.filter(col(\"label_move\") == False).filter((col(\"move_main_bert_prob\") < 0.01) & (col(\"move_postal_bert_prob\") < 0.01)).count()\n",
    "print(f\"TN count: {tn_moves}\")\n",
    "\n",
    "fp_moves = df_bert_spark.filter(col(\"label_move\") == False).filter((col(\"move_main_bert_prob\") >= 0.01) | (col(\"move_postal_bert_prob\") >= 0.01)).count()\n",
    "print(f\"FP count: {fp_moves}\")\n",
    "\n",
    "fn_moves = df_bert_spark.filter(col(\"label_move\") == True).filter((col(\"move_main_bert_prob\") < 0.01) & (col(\"move_postal_bert_prob\") < 0.01)).count()\n",
    "print(f\"FN count: {fn_moves}\")\n",
    "\n",
    "precision_moves = tp_moves / (tp_moves + fp_moves)\n",
    "print(f\"Precision: {precision_moves}\")\n",
    "Accuracy = (tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)\n",
    "recall_moves = tp_moves / (tp_moves + fn_moves)\n",
    "print(f\"Recall: {recall_moves}\")\n",
    "print(f\"Accuracy: {(tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)}\")\n",
    "\n",
    "move = [('moves', tp_moves, tn_moves, fp_moves, fn_moves, precision_moves, recall_moves, Accuracy)]\n",
    "f3 = spark.createDataFrame(data=move, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e4cb586-713e-4a15-ab08-bd17c93ae2bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP count: 24673\nTN count: 197310\nFP count: 63429\nFN count: 76302\nPrecision: 0.28005039613175636\nRecall: 0.24434761079475117\nAccuracy: 0.6136975621623714\n"
     ]
    }
   ],
   "source": [
    "#move, threshold 0.005\n",
    "tp_moves = df_bert_spark.filter(col(\"label_move\") == True).filter((col(\"move_main_bert_prob\") >= 0.005) | (col(\"move_postal_bert_prob\") >= 0.005)).count()\n",
    "print(f\"TP count: {tp_moves}\")\n",
    "\n",
    "tn_moves = df_bert_spark.filter(col(\"label_move\") == False).filter((col(\"move_main_bert_prob\") < 0.005) & (col(\"move_postal_bert_prob\") < 0.005)).count()\n",
    "print(f\"TN count: {tn_moves}\")\n",
    "\n",
    "fp_moves = df_bert_spark.filter(col(\"label_move\") == False).filter((col(\"move_main_bert_prob\") >= 0.005) | (col(\"move_postal_bert_prob\") >= 0.005)).count()\n",
    "print(f\"FP count: {fp_moves}\")\n",
    "\n",
    "fn_moves = df_bert_spark.filter(col(\"label_move\") == True).filter((col(\"move_main_bert_prob\") < 0.005) & (col(\"move_postal_bert_prob\") < 0.005)).count()\n",
    "print(f\"FN count: {fn_moves}\")\n",
    "\n",
    "precision_moves = tp_moves / (tp_moves + fp_moves)\n",
    "print(f\"Precision: {precision_moves}\")\n",
    "Accuracy = (tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)\n",
    "recall_moves = tp_moves / (tp_moves + fn_moves)\n",
    "print(f\"Recall: {recall_moves}\")\n",
    "print(f\"Accuracy: {(tp_moves + tn_moves) / (tp_moves + fp_moves + fn_moves + tn_moves)}\")\n",
    "\n",
    "move = [('moves', tp_moves, tn_moves, fp_moves, fn_moves, precision_moves, recall_moves, Accuracy)]\n",
    "f3 = spark.createDataFrame(data=move, schema = ['category', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c63a4e1-9fcf-4505-bb8b-98c0c811e956",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# CONCLUSION:\n",
    "## Guided Bertopic achieved simliar but a bit less performance on evaluation of cancel and move labels than the Guided LDA model.    \n",
    "## Other comparsions:    \n",
    "### Guided LDA model only take into account of the co-occurance of the words while bertopic take into account of the sequence and semantics of the sentences.     \n",
    "### However, the Guided LDA model yeilded fixed number of topics as we provided in seeds_list while bertopic did not. \n",
    "### Also bertopic tend to assign huge number of conversations to 'topic -1' meaning noises and outliers since by default it is using density based clustering HDBSCAN as clustering algorithm. So unless one decease the min_cluster_size paramter of HDBSCAN or switch to algorithms like k-means, otherwise 'topic -1' 's probability tend to dominate over 30 topics in this specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afd653c3-d28a-4ddf-8838-ff211be66a47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bertopic_for_spotting_cancel_and_move_conversations_VS_GLDA",
   "notebookOrigID": 2351514327945841,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
